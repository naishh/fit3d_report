% set ignorecase



% todo's
% iets schrijven over datasets
% rectification is not always accurate, explain consequences



%TODO pipeline rectification process
%
% 		motion estimation
% 		scale estimation
% 			produces MAP
% 		plane fitter
% 			produces normal of wall
% 		edgeIm or houghlines reprojection
%


% list of figures
% -bar and barh in fig mergen
% -grayvalues voting
%	- values that fall out of cluster are displayed striped
% -grayvalues voting with clusterlines
% 	- or clustervalues in colored bar graph


\section{Window detection}
\subsection{Updated/New since 28-3-20012}
explanation diff types of connected corners
Future work -> Window alignment refinement
nummeric evaluation of connected corner result in Discussion 

\subsection{Q}
Is it useful to include the connected corner result of the occluding tree?
\ref{fig:w_Dirk5_ImcCorner_cCorner.eps}

% TODO explain efficiency of Houghline coordinate transformation (instead of
% transforming the image
\label{chap:windowDetection}
\subsection{Introduction}
This chapter deals with one of the tasks of semantic urban scene interpretation, Window detection. 
Semantic interpretation of urban scenes is used in a wide range of applications.

\paragraph{3d City models} 
	Manual creation of 3d models is a time consuming and expensive procedure.
	Therefor semantic models are used for semi automatic 3d
	reconstruction/modelling.
	 %[Procedural Modeling of Buildings].  
	The semantic understanding is also used in 3d city models which are
	generated from aerial or satellite imagery.  The detected (doors and)
	windows are mapped to the model to increase the level of detail. 
	Some other applications can automatically extract a CAD-like model of
	the building surface.

\paragraph{Historical buildings documentation and deformation analysis}
	In some field of research, Historical buildings are documented. The complex
	structures that are contained in the facades are recorded and reconstructed.
	Window detection plays a central role in this. 
	Another field of research is the analysis of building deformation in areas
	containing old buildings.  Window detection provides information about the
	region of interest that could be tracked over time for an accurate
	deformation analysis.
	%[A SEMI-AUTOMATIC IMAGE-BASED MEASUREMENT SYSTEM]


\paragraph{Interactive 3d models}
	There are some virtual training applications that are designed for
	emergency response who require interaction with a 3d model.  
	For the simulation to be realistic it is important to have a model that is
	of high visual quality and has sufficient semantic detail (i.e. contains
	windows).  This is also the case for a fly-through visualization of a street with
	buildings.
	Other applications that require semantic 3d models are virtual tourism,
	visual impact analysis, driving simulation and military simulation systems.
%todo afbeelding uit pag 3 halen en hier plakken
%http://www.rgi.nl/downloads/files/Shi Pu.pdf

\paragraph{Augmented reality}
	Some mobile platforms apply augmented reality using facade and window
	detection to make a accurate overlay of the building. An example overlay is the
	same building but 200 years earlier.  Semantical information is used to not
	only identify a respective building, but also find his exact location in the
	image.  The accuracy and realistic level of the 3d model are vital for a
	successful simulation.  And because the applications are mobile, very fast
	building understanding algorithms are required.  Window
	detection plays an important role in these processes.

\paragraph{Building recognition and urban planning}
	Building recognition is used in the field of urban planning where the semantic 3d
	models are used to provide important references to the city scenes from the
	street level.
	Building recognition is done using large image datasets where the
	buildings are mostly described by local information descriptors.  
	Some approaches try to describe the 3D building with laser range data. Some methods fuse the laser data with
	ground images. However those generated 3D models are a mesh structure which doesn't make the facade structure explicit.
	For a more accurate disambiguation, other types of contextual information are
	desired.  The semantical interpretation of the facade can provide this need.
	In this context, window detection can be used as a strong discriminator.\\

%TODO write big part about what is new /different / importand in my approach


We can conclude that window detection plays an important role in the
interpretation of urban scenes and is applied in a wide range of domains.  This
chapter presents two developed methods for robust window detection.

We start with discussing related work and putting our work in context.  Then we
describe a window detection approach that is invariant to viewing direction.
After this we present our second method that assumes orthogonal and aligned
windows.  Finally we show and discuss results. 


\subsection{Related work}
A large amount of research is done on semantical interpretation of urban scenes. First we
discuss related work that has a big overlap with our approach in detail.
After this, we briefly discuss the research that is done on window detection
using other approaches.


\subsubsection{Similar approaches}
Pu and Vosselman \cite{Pu_refiningbuilding}
use laser images together with Hough line extraction to reconstruct facade details.  They solve inconsistency between laser and image data and improve the alignment of a 3d model with a matching algorithm.  In one of the matching strategies they compare the edges of a 3d model to Hough lines of ground images.
They match the lines by comparing the angle, location and length difference of the model edges with the extracted Houghlines.  These criteria is also used in our approach.\\
They also detect windows and use them to provide a significant better alignment of the 3d model.
The windows are extracted from the holes from laser points of a wall, these results where far from accurate.\\
To summarize, the work of Pu and Vosselman provides a useful practical application of window detection and it amplifies the need for a robust window detection technique that is independent of laser data.\\


In \cite{Recky_kmeans} Recky et all developed a window detector that is build on
the primary work of Lee and Nevatia \cite{Lee_extraction} (which is discussed
next).
In order to be able to assume aligned windows they rectify the facade.  After this they apply a threshold on an orthogonal projection of the extracted edges. 
For example they use a vertical edge projection to establish the horizontal division of the windows.
% todo sentence below in differnet alinea and more detail
This is very similar to our approach, although we only project line segment endpoints.\\
The next step, labeling the areas containing windows, is however very different as they use color to disambiguate the windows.
To be more precise, they convert the image to CIE-Lab color space and use k-means to classify the windows.
Although this method is robust, both color transformation and k-means clustering are very computational expensive.
In our method we use the same source, edge information, for the window alignment and for the window labeling.
As we don't require color transformation and only apply math on line segment
endpoints, our algorithm performs in real-time.

As in the work of Recky et all \cite{Recky_kmeans} Lee et all
\cite{Lee_extraction}
perform orthogonal edge projection to find the window alignment.  As different
shape of windows can exist in the same column, they use the window alignment as
a hypothesis.  Then, using this hypothesis, they perform a refinement for each
window independently. More on this in Future research.

%%NEW PAPERS 
%[A model-based method for building reconstruction]
	%brute force matching of window primitives
	%make 3d models and recover the geometry of a building


\subsubsection{Other approaches}
Muller et all \cite{Muller_procedural} detect symmetry in the building. The
symmetry is detected in the vertical (floors) and horizontal (window
rows) direction.
The use shape grammars to divide the building wall in tiles, windows, doors etc.
The results are used to derive a 3d model of high 3d visual quality.
%todo insert an image of this paper of the nice geometry (ingevallen raam)

Using a thermal camera, Sirmacek \cite{Sirmacek_thermal}
detects heat leakage on building walls as an indicator for doors or windows.
Windows are detected with L-shaped features as set of \emph{steerable filters}.
The windows are grouped using \emph{perceptual organization rules}.

Ali et all \cite{Ali_facades}
describe the windows with Haar like features which are fed into a (Ada boost) cascaded decision tree.





% handige note
% \paragraph{Facade classification}
% That shows the importance of the facade classification
% study in three-dimensional city modeling. Burochin et al. [3]
% proposed a segmentation method to detect repetitive structures
% like windows in close-range optical images. For segmentation
% they defined a model by considering shape and reflectance
% Fig. 1. Overview of the proposed approach (Facade1 test image, segmentation
% result with facade graph, and classification result of the algorithm
% respectively.)
% of a window, then they applied matching process to find
% correspondence between model and image. In [2], Ali et
% al. gave summary of the researches on window detection.
% They also proposed a window detection system based on
% cascade classifiers. In a following study, Ali et al. proposed
% a system to detect windows in laser scanner data. The laser
% Therefore, they use these variations to detect windows [1]. Lee
% and Nevatia [8] proposed a robust system to detect windows in
% optical images. They extracted window boundaries searching
% for structures that satisfy regularity and symmetry rules. In
% addition to that, they extract three-dimensional models of
% windows by searching for image features. Teboul et al. [13]
% used shape grammars towards fixed tree representations which
% are able to capture a wide variety of building topologies
% for detailed facade segmentation. They obtained very high
% performance even for buildings which are partially occluded
% or which appears under different illumination conditions.





% todo tjoint article quoten


% todo find good location in thesis for this
\fig{w_spil6ImOri.eps}{Original image}{0.6}
\fig{w_Spil1TransCrop1_ImOri.eps}{Rectified image}{0.45}
\fig{w_Spil1TransCrop1_ImEdge.eps}{Result edge detection}{0.45}
\fig{w_Spil1TransCrop1_ImHoughResult.eps}{Houghlines with endpoints}{0.45} 




\subsection{Method I: Connected corner approach} 
% todo begin with motivation

%Because the viewing point isn't assumed to be frontal, we we set the 

\subsubsection{Situation and assumptions}
We introduce the concept \emph{connected corner}, this is a corner that is 
connected to a horizontal and vertical line.  
In this method we search for connected corners based on edge information.
The connected corners give a good indication of the position of the windows, as 
a window consists of a complex structure involving a lot of connected horizontal
and vertical lines. 

In this approach the viewing direction is not required to be frontal.
The windows could be arbitrarily located and they don't need
to be aligned to each other neither to the X and Y axis of the image.

%voting
%the connected lines give a direction

\subsubsection{Method}
\paragraph{Edge detection and Houghline extraction}
Edge detection is done as is described in chapter 
\emph{(not included chapter)} % todo
From the edge image we extract two different groups of Houghlines, horizontal and % todo why?
vertical.  We set the $\theta$ bin ranges in the Hough transform that control the
allowed angles of the Houghlines to extract the two groups. The horizontal group
has a range of [-30..0..30] degrees, where 0 presents a horizontal line. The vertical
group has a range of [80..90..100] degrees. These ranges seem
to work well on an empirical basis for all datasets.
The results of two images can be seen in Figure \ref{fig:w_Spil1TransCrop1_ImEdge.eps} and
 \ref{fig:w_Spil1TransCrop1_ImHoughResult.eps}.

\paragraph{Extract connected corners}
\fig{cCornerTypes}{First row: different type of connected corner candidates. Second row: the
result the clean connected corner}{0.5} As windows contain complex structures
the amount of horizontal and vertical houghlines is large at these locations.
A horizontal and vertical line is often connected in a corner of a window.  In
this approach we pair up these horizontal and vertical lines to determine
\emph{connected corners} that indicate a window.

Often a connected corner contains a small gap or an extension wich we tollerate,
these cases are illustrated in Figure \ref{fig:cCornerTypes} in the top row.
A horizontal gap a vertical and horizontal gap and a vertical alongation. The
cleaned up corners are given in the bottom row.  When the horizontal and
vertical lines intersect, the gap distance is $D=0$.  When the lines do not
intersect, the distance between the intersection point and the endpoint of the
lines is measured, this is illustrated as dotted lines in Figure
\ref{fig:cCornerTypes}.  Next, $D$ is compared to a \emph{maximum intersection
distance} threshold $midT$.  And if $D<=midT$, the intersection is close enough
to form a connected corner.\\

After two Houghlines are classified as a connected corner, they are extended or
trimmed, depending on the situation. The results are shown in the second row in
Figure \ref{fig:cCornerTypes}.
In Figure \ref{fig:cCornerTypes}(I)  the horizontal line is extended.  Figure
\ref{fig:cCornerTypes}(II) shows that the vertical line is trimmed.  In Figure
\ref{fig:cCornerTypes}(III) both lines are extended.  At last, Figure
\ref{fig:cCornerTypes}(IV) shows how both lines are trimmed.
%todo nieuw fig maken cCornerTypes: rood is horizontaal ook onderste rij


\paragraph{Extract window areas}
To retrieve the actual windows, each connected corner is mirrored along its
diagonal. The connected corner now contains four sides which form a 
quadrangle window area.
All quadrangles are filled and displayed in Figure
\ref{fig:w_Dirk6_ImcCorner_windowFilled.eps} and
\ref{fig:w_Dirk5_ImcCorner_windowFilled.eps}.

%todo numeric evaluation of the windows


\subsection{Method II: Histogram based approach} 
\subsubsection{Introduction}
From the previous chapter we know that from a series of images, a 3D model of a
building can be extracted. Furthermore we saw that using this 3D model the
scene could be converted to another viewing point. 

%todo instead of frontal: rectified
For accurate and robust window detection we projected the scene to a frontal
view of a building, where a building wall appears orthogonal. This frontal
view enables us to assume orthogonality and alignment of the windows. We
exploit this properties to build a robust window detector.
First we determine the the alignment of the windows and
then we label the areas that contain the windows. 


\subsubsection{Situation and assumptions}
To be more precise in our assumptions, we assume the windows have orthogonal sides.  Furthermore we
assume that the windows are aligned. This means that a row of windows share the
same height and $y$ position. For a column of windows the width and $x$
position has to be equal.  Note that this doesn't mean that all windows have the
share the same size.

\subsubsection{Method}
The extraction of the windows is done in different steps. 
First the alignment of the windows is determined, this is based on collecting
the Houghlines' start and endpoints. Then we use this alignment to divide the
image in window or not window regions.  Finally these regions are classified
and combined which gives us the windows.


\fig{w_Spil1TransCrop1_ImHibaap.eps}{(smoothed) Histograms and window alignment lines}{0.45}
\paragraph{Extract Window alignment}
%explain pipe line
%(color transform)
%edge extraction
%Houghline extraction
We introduce the concept alignment line. We define this as a horizontal or
vertical line that aligns multiple windows. In Figure
\ref{fig:w_Spil1TransCrop1_ImHibaap.eps}
we show the alignment lines as two groups, horizontal (red) and
vertical (green) alignment lines.  The combination of both groups give a grid of
rectangles that we classify as window or non-window areas.\\

% MOTIVATION
How do we determine this alignment lines? We make use of the fact that among a
horizontal alignment line a lot of horizontal Houghlines start and end (see red
crosses in Figure \ref{fig:w_Spil1TransCrop1_ImHoughResult.eps}. For the vertical alignment lines
the number of vertical Houghline start and ends is high (see green crosses in
Figure \ref{fig:w_Spil1TransCrop1_ImHoughResult.eps}.\\

We begin by extracting the coordinates of the endpoints of the Hough transformed line
segments. We store them in two groups, horizontal and vertical.% (crosses in Figure \ref{fig:w_Spil1TransCrop1_ImHoughResult.eps}). 
We discard the dimension that is least informative by project the coordinates to
the axis that is orthogonal to its group. 
This means that for each horizontal Houghline two coordinates are projected to the X
axis and for each vertical Houghline two coordinates are projected to the Y
axis. We have now transformed the data in two groups of 1 dimensional
coordinates which represent the projected position of the Houghlines.\\

Next we calculate two histograms H(orizontal) and V(ertical), containing respectively
$w$ and $h$ bins where $w x h$ is the dimension of the image.  The histograms
are presented as small yellow bars in Figure \ref{fig:w_Spil1TransCrop1_ImHibaap.eps}.

The peaks are located at the positions where an increased number of Houghlines
start or end.  These are the interesting positions as they are highly correlated
to the alignment lines of the windows. 

It is easy to see that the number of peaks is fare more then the desired number of alignment lines.
A common solution would be to decrease the number of bins of the histograms. A
disadvantage of this method is that this comes with a price, it decreases the accuracy. Therefor
we keep the maximum resolution and, instead, smooth the values using a moving average filter.
The result, red lines in Figure \ref{fig:w_Spil1TransCrop1_ImHibaap.eps}
, is a smooth function which contains the right number of peaks. The peaks
are located at the average positions of the window edges. Next step is to
calculate the peak areas and after this the peak positions. 

Before we find the peak positions we extract the peak \emph{areas} by thresholding the
function. To make the threshold invariant to the values, we set the threshold to 0.5 $\cdot$ max Peak. 
(This value works for most datasets but is made up and can be altered).
%The two thresholds are presented as black dotted lines in Figure \ref{fig:w_Spil1TransCrop1_ImHibaap.eps}.\\
Next we create a binary function P that returns 1 for positions that are contained in
a peak, i.e. are above the threshold, and 0 otherwise.
% TODO latex, afkijken locate my plate
%P(x)  { 1, H(x)>t
%	  { 0, H(x)<=t
We detect the peak areas by searching for the positions where P = 1
(where the function passes the threshold line). 
If we loop through the values of P we detect a peak-start on position $s$ if ${P(s-1),P(s)}={0,1}$
and a peak-end on $e$ if ${P(e-1),P(e)}={1,0}$. 
I.e. if P = 0011000011100, then two peaks are present. The first peak covers positions $(3,4)$, 
the second peak covers $(9,10,11)$.\\

Having classified the peak areas, the next step is to extract the peak positions. 
Each peak area has only one peak and, since we used an average smoothing filter, the shape of 
the peaks are often concave. Therefor we extract the peaks by locating the max of each peak area. 
These locations are used to draw the window alignment lines, they can be seen
as dotted red lines and dotted green lines in Figure \ref{fig:w_Spil1TransCrop1_ImHibaap.eps}.

The image is now divided in a grid of rectangular areas. The next challenge is to 
classify the areas as window and non-window areas: the window classification.

\paragraph{Window classification}
Instead of classifying each rectangle independently we classify full rows and
columns as window or non-window areas.  This approach results in more accurate
classification as it uses a full row and column as evidence for a singular
window. 

The method exploits the fact that the windows are assumed to be
aligned.
A row that contains windows is remarkable by its high amount of vertical
Houghlines, Figure \ref{fig:w_Spil1TransCrop1_ImHoughResult.eps}
(green). For the columns the number of horizontal Houghlines
 (red) is high at window areas.  We use this property to classify 
 the rows/columns. 

For each row the number of vertical Houghline pixels that lie in this row are summed up.
(Remark that with this method we take both the length of the Houghlines and amount of Houghlines 
implicitly into account.)

To prevent the effect that the size of the row influences the outcome, this total value
is normalized by the size of the row.
\[\forall Ri\in \{1..numRows\} : R_i = \frac{HoughlinePxCount}{R_i^{width} \cdot R_i^{height}}\]

Leaving us with $||R||$ (number of rows) scalar values that give a rank of a row begin a window area or not.
This is also done for each column (using the normalized horizontal amount of
Houghlines pixels) which leaves us with $C$.

\fig{w_Spil1TransCrop1_ImClassRectBarh.eps}{Normalized vertical Houghline pixel count of
the rows (R)}{0.6}
If we examine the distribution of $R$ and $C$, we see two clusters appear: one with
high values (the rows/columns that contain windows) and one with low values (non window
rows/columns). For a concrete example we displayed the values of $R$ in Figure \ref{fig:w_Spil1TransCrop1_ImClassRectBarh.eps}.
Its easy to see that the high values, row 4,5,7,8,10 and 11, correspond to the
six window row areas in Figure \ref{fig:w_Spil1TransCrop1_ImClassRect.eps}.

How do we determine which value is classified as high?  A straight forward
approach would be to apply a threshold, for example 0.5 would work fine.
However, as the variation of the values depend on (unknown) properties like the
number of windows, window types etc., the threshold maybe classify insufficient
in another scene.  Hence working with the threshold wouldn't be robust. 

Instead we use the fact that a row is either filled with windows or not, hence
there should always be two clusters.  We use \emph{$k$-means} clustering (with
$k=2$) as the classification procedure.
%todo ref
This results in a set of Rows and Columns that are classified as window an
non-window areas.

The next step is to determine the actual windows $W$.
A rectangular area $w\in W$ that is crossed by $R_j$ and $C_k$ is classified as a
window iff \emph{$k$-means} classified both $R_j$ and $C_k$ as window areas. These are displayed in 
 Figure \ref{fig:w_Spil1TransCrop1_ImClassRect.eps} as green rectangles.

The last step is to group a set of windows that belong to each other. This is done by 
grouping adjacent positively classified rectangles. These are displayed as red
rectangles in Figure \ref{fig:w_Spil1TransCrop1_ImClassRect.eps}.

As the figure gives a binary representation of the windows it is not possible
to see the probabilities behind the classification.
Therefor we developed a probabilistic function. 
\[P(R_i) = \frac{R_i}{max(R)}\]
\[P(C_i) = \frac{C_i}{max(C)}\]
\[P(w) = \frac{P(R_i) + P(C_i)}{2}\]
As you can see $P$ is normalized, this is to ensure the value of the maximum
probability is exactly 1. The results can now be relatively interpreted, e.g. if the rectangle's $P=0.5$
then the system nows for 50 percent sure it is a window, compared to its best window ($P=1$). 
And, as the normalization implies this, there are always one or more window with $P=1$. 

To get insight about the probabilities that lie behind the individual rows and columns
we designed another representation in Figure \ref{fig:w_Spil1TransCrop1_ImClassRectGrayscaleProb.eps}
The whiter the area the more probable a rectangle is classified as a window.



\subsection{Results}
We tested both methods on different datasets.

\newpage
\fig{w_Spil1TransCrop1_ImClassRectGrayscaleProb.eps}{Window classification probabilities, white means high.}{0.45}

\fig{w_Dirk6_ImEdge.eps}{Edge detection}{0.6}
\fig{w_Dirk6_ImHoughResult.eps}{Result of $\theta$ constrained Hough transform}{0.6}
\fig{w_Dirk6_ImcCorner_cCorner.eps}{Found connected corners}{0.6}
\fig{w_Dirk6_ImcCorner_windowFilled.eps}{Window regions}{0.6}

\fig{w_Dirk5_ImEdge.eps}{Edge detection (with occluding tree)}{0.6}
\fig{w_Dirk5_ImHoughResult.eps}{Result of $\theta$ constrained Hough transform (with occluding tree)}{0.6}
\fig{w_Dirk5_ImcCorner_cCorner.eps}{Found connected corners (with occluding tree)}{0.6}
\fig{w_Dirk5_ImcCorner_windowFilled.eps}{Window regions (with occluding tree)}{0.6}


% old dataset:
%\fig{w_spil6cCornerImEdge.eps}{Edge detection}{0.6}
%\fig{w_spil6cCornerImHoughResult.eps}{Result of $\theta$ constrained Hough transform}{0.6}% todo theta constrain
%\fig{w_spil6cCornercCorner.eps}{Found connected corners}{0.6}
%\fig{w_spil6cCornerWindows.eps}{Connected corner as windows}{0.6}
%\fig{cCornerSpilTrans1.eps}{Found connected corners on the rectified image}{0.45}

\fig{w_Spil1TransCrop1_ImClassRect.eps}{Classified rectangles}{0.45}

\fig{w_SpilFrontal6345_crop1_ImOri.eps}{Original Image}{0.6}
\fig{w_SpilFrontal6345_crop1_ImHibaap.eps}{Window alignment lines and histograms}{0.6}
\fig{w_SpilFrontal6345_crop1_ImClassRect.eps}{Classified rectangles}{0.6}



\emph{TODO include images other datasets} \\
\emph{todo compair methods and explain differences}


\subsection{Discussion}  % (What do my results mean to me and why)
\emph{ todo discuss results }
Figure \ref{fig:w_Dirk6_ImcCorner_windowFilled} contains 110 windows of which
are 109 detected, this is 99\%. Furthermore there are some False Positive areas,
this is about 3 \%.  The window on the right top isn't detected, this is because
he is smaller then our minimum window width.

\paragraph{Method I: Connected corner approach} 
% todo ref
The big advantage of this method is that it doesn't require the windows to be aligned.
Furthermore it's robust to a variation in window sizes and types. This makes
this approach suitable for a wide range of window scenes where no or few prior
information about the windows is known.
\emph{TODO}


\paragraph{Method II: Histogram based approach} 
% todo also works on multiple window types
One drawback is that the outcome is non-deterministic, as it depends on to the
random initialization of the cluster centers.

\emph{TODO}\\
% TODO Ref biblograyhf

\paragraph{Occlusion}
\label{lab:occlusion}
If the image isn't the frontal view of the buildingwall we project the image 
see section ?%todo section rectification
This projection comes with some difficulties, occlusion.  In a few cases an
buiding wall extension (middle of figure \ref{fig:w_spil6ImOri.eps}) a drainpipe
or the building wall itself is occluding a part of the window.  The less frontal
the view, the more occlusion negatively effects the cleanness of the projection.
However, this occlusion artefact is in most cases no problem as the system
combines the windows probabilities.  

\subsection{Conclusion}
We showed that projecting the image to a frontal view is a good preprocessing
step of a robust window detector.
\emph{TODO}
%todo

\subsection{Future work}
\subsubsection{Method I: Connected corner approach} 
It would be nice to have a clustering algorithm that groups connected corners to
a window. For this method it would be useful to assume the window size as this
correlates directly to the inter-cluster distance.\\

It would also be nice to incorporate not only the center of the connected corner
as a parameter of the cluster space but also the length and position of the of
the connected corners' horizontal and vertical line parts.  The inter cluster
distance and the number of grouped connected corner could form a good source for
the probability that a window is found.

% todo uitzoeken of ik dit niet al doe
We only developed L-shaped connected corners, it would be nice to connect more
parts of the window to form U shaped connected corners or even complete rectangles.\\
The later is difficult because the edges are often incomplete due to for example occlusion 
or the angle of viewing.


\subsubsection{Method II: Histogram based approach} 
It would be nice to investigate the effect of the occlusion and to exploit the
robustness of the window detector under extreme viewing angles.
For example the viewing angle could be plotted against the percentage of
correct detected windows.
\emph{TODO}

% todo 

\paragraph{Window alignment refinement}
To get more accurate result or to handle scenes with poor window alligment a refinement procedure could be applied.
As mentioned in the related work, Lee et all \cite{Lee_extraction} applied window refinement.
Although this comes with accurate results, the iterative refinement is a
computational expensive procedure. 
It would be nice to have a dynamic system that is aware of this 
accuracy and computational time trade of. A system that only refines the results when the recources are available.
For example if a car is driving and uses window detection for building recognition the refinement is disabled.
But if the car is lowering speed the refinement procedure could be activated.
Resulting in accurate building recognition which opens the door for augmented reality.








% todo put in appendix or in a chapter devoted to projecting/rectifying
\subsection{Efficient Projecting} 
As we are interested in the frontal view of the building, it would be straight
forward to project the original image. However this is computational
very expensive as each pixel needs to be projected. To keep the computational cost to a minimum we project only the
Houghlines. The edge detection and Houghline extraction is done on the original
unprojected image. We only project the Houghline segment
endpoints. If $h$ is the number of Houghlines, the number of projections is $2h$
When we project the original image this is $w$ x $h$ where w,h are the dimensions of
the image. To give an indication, for the \emph{Spil} dataset %TODO
this means 600 projections in stead of 1572864.\\
% todo good location
However for the purpose of display we also presented the rectified images.
% todo backprojection




% title: Graph Theory and Mean Shift Segmentation Based Classiﬁcation of Building Facades
% 
% Most of the previous algorithms are computationally expensive and not suitable for real time applications. Because
% of the requirements of real-time applications robust and fast
% classiﬁcation of facades is still an open research topic
% 
% 
% Image-based Procedural Modeling of Facades
% 
% 
% 
% refs:
% (canny edge detector:)
% 
% Canny, J., 1986. A computational approach to edge detection.
% IEEE Transactions on pattern analysis and machine intelli-
% gence pp. 679–698.
% 
