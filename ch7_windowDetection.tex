\section{Window detection}
% TODO explain efficiency of houghline coordinate tranformation (instead of
% transforming the image
\label{chap:windowDetection}
\subsection{Introduction}
From the previous section we saw that from a serie of images a 3D model of a
boulding could be extracted. Furthermore we saw that with the 3D information the
scene could be viewed from another viewing direction. 

We projected the scene to a frontal view of a building, where a building wall appears
orthogonal, and show what interesting posibilities this opens.
One example is robust window detection.
In this section we present three developed method for robust window detection
and discuss the effect of the scene tranformation.

We begin with an approach that is invariant to viewing direction.
Then we present our second method that assumes orthogonal and aligned windows.
At last we show the power of combining both methods.


\subsubsection{Related work}
%TODO

\subsection{Edge detection and Houghline extraction} 
% this is decribed in a early chapter.
Edge detection and Houghline extraction is done as is described in chapter
%TODO.
\fig{hibaapOri.eps}{Original image}{0.4}
\fig{hibaapEdge.eps}{Result edge detection}{0.4}
We are interested in the frontal view of the building and it would be straight
forward to project the original image. However this is very computational
expensive. To keep the computational cost to a minimum we project only the
Houghlines. The edge detection and houghline extraction is done on the original
unprojected image. Leaving the projection done on the Houghline segment
endpoints. If $h$ is the number of Houghlines the number of projections is $2H$
When we project the original image this is $wxh$ where w,h are the dimensions of
the image. To give an indication for dataset %TODO
this means 600 projections in stead of 1572864.

\subsection{Method I: Connected corner approach} 
\subsubsection{Situation and assumptions}
In this approach the windows could be arbitrairly located and don't need
alignment.
%TODO

\subsection{Method II: Histogram based approach} 
\subsubsection{Situation and assumptions}
In this method we assume the wall containing the windows to be rectified.
To be more precise we assume the windows to have orthogonal sides.
Furthermore we assume the windows to be alligned.

\subsubsection{Method}
The main idea is that we extract the alignment of the windows based on
calculating histograms of the Houghlines endpoints.

\fig{hibaapHist.eps}{(smoothed) Histograms and window alignment
lines}{0.4}
\paragraph{Alignment lines}
%explain pipe line
%(color transform)
%edge extraction
%houghline extraction
We introduce the concept alignment line. We define this as a horizontal or
vertical line that alignes multiple windows. In Figure
\ref{fig:hibaapHist.eps}
we represent the alignment lines as two groups, horizontal (red) and
vertical (green) alignment lines.  The combination of both groups give a grid of
rectangles that have to be classified as window or non-window.
First we explain the extraction of the alignment lines which consist of several
steps.

We begin by extracting the coordinates of the endpoints of the Hough transformed line
segments. We store them in two groups, horizontal and vertical (crosses in Figure
\ref{fig:hibaapHough.eps}). 
\fig{hibaapHough.eps}{Houghlines with endpoints}{0.4} 


We project the coordinates to the axis that is orthogonal to the group. This means
that the horizontal Houghlines are projected to the X axis and the vertical
Houghlines are projected in the Y axis, leaving the data in two groups of 1
dimensional coordinates.

We calculate two histograms H(orizontal) and V(ertical), containing respectively
$w$ and $h$ bins where $w x h$ is the dimensions of the image.  The graphs of
the histograms are presented as small yellow bars in Figure
\ref{fig:hibaapHist.eps}

The peaks are located at the positions where an increased number of Houghlines
start or end.  These are the interested positions as they are highly correlated
to the alignment lines of the windows. 

As can be seen the number of peaks is fare more then the desired number of alignment lines 
A common solution would be to decrease the number of bins of the histograms. A
disadvantage of this method is that this also decreases the accuracy. Therefor
we keep the maximum resolution and smooth the function using a using a moving
average filter.
% with a span of %TODOthe width of 
The result, red lines in Figure \ref{fig:hibaapHist.eps}
, is a smooth function which contains the right number of peaks. Also the peaks
are located at the right positions. Next step is to calculate the exact positions of these
peaks?

Before we find the peak positions we extract the peak \emph{areas} by thresholding the
function, see the black dotted line in Figure \ref{fig:hibaapHist.eps}
% the threshold is set to 20% of max?
We create a binary function P that returns 1 for positions that are contained in
a peak, i.e. are above the threshold, and 0 otherwise.
% TODO latex, afkijken locate my plate
%P(x)  { 1, H(x)>t
%	  { 0, H(x)<=t

We detect the peak areas by searching for the positions where the function
passes the threshold line. 
If te loop through the values of P we detect a peak start on position $s$ if {P(s-1),P(s)}={0,1}
and a peak ends on $e$ if {P(e-1),P(e)}={1,0}. 
I.e. if P = 0011000011100, then two peaks are present. The first covers positions {3,4}, 
the second covers {9,10,11}. 

Having classified the peak areas, the next step is to extract the peak positions. 
Each peak area has only one peak and, since we used an average smoothing filter, each
peak area has a concave shape. Consiquently we can easily extract the peaks
by locating the max of each peak area. 
On these locations we have drawn the window alignment lines, dotted red and yellow lines
in Figure \ref{fig:hibaapHist.eps}

The image is now devided in a grid of rectangular areas. The next challenge is to 
classify the rectangles as a window or non-window area.


Images:
edge image
example image of start end coordinates Houghlines


\subsubsection{Future work}
Some alternative ideas to classify the rectangles as window or non-window
\begin{itemize}
	\item count edge pixels in a row pixels
		many edge pixels classify the row a row of windows
		collect the rows between the corner points
	\item calc the variance of a row
		hight variance means windows
		low variance means bricks
\end{itemize}


\subsection{Method III: Feature detection approach}
	TODO explain contribution and method of multiscale harris corner detector

\subsection{Fusing the methods}

\subsection{Results}
\subsection{Discussion}  % (What do my results mean to me and why)
\subsection{Conclusion and Future work}


%TODO 
% find a way to compair accuracy window detector
% compair methods, show robustness


% title: Graph Theory and Mean Shift Segmentation Based Classiﬁcation of Building Facades
% 
% Most of the previous algorithms are computationally expensive and not suitable for real time applications. Because
% of the requirements of real-time applications robust and fast
% classiﬁcation of facades is still an open research topic
% 
% 
% Image-based Procedural Modeling of Facades
% 
% 
% 
% refs:
% (canny edge detector:)
% 
% Canny, J., 1986. A computational approach to edge detection.
% IEEE Transactions on pattern analysis and machine intelli-
% gence pp. 679–698.
% 
