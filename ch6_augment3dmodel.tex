\documentclass[10pt]{article}

\usepackage[usenames,dvipsnames]{pstricks}
\usepackage{epsfig}
\usepackage{pst-grad} % For gradients
\usepackage{pst-plot} % For axes


\usepackage{graphicx, subfigure}

\usepackage{amsmath} % for the argmin
\newcommand{\argmax}[1]{\underset{#1}{\operatorname{argmax}}}
\newcommand{\argmin}[1]{\underset{#1}{\operatorname{arg\ min}}}
\setlength{\parindent}{0in}
\include{commands}

% TODO
% put this in one of the chapters befor this chapter:
% The 3D model comes from a top view googlemaps blabal
% The model is of infinite height
% an intro which answers the question:
% detail of the problem, why is this such a interesting problem
% what did others and how is my work related?

\title{\sc Improve 3D models from 2D images}

\author{T. Kostelijk\\mailtjerk@gmail.com}

\begin{document}
\maketitle


\section{Test}

% Generated with LaTeXDraw 2.0.8
% Fri Aug 05 21:57:11 CEST 2011
% a
\scalebox{1} % Change this value to rescale the drawing.
{
\begin{pspicture}(0,-1.005)(4.473328,1.4)
\psframe[linewidth=0.01,dimen=outer](3.0,1.4)(1.5,-1.0)
\psline[linewidth=0.01cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(3.0,-1.0)(1.1,0.6)
\psline[linewidth=0.01cm,arrowsize=0.05291667cm 2.0,arrowlength=1.4,arrowinset=0.4]{->}(1.5,-1.0)(0.0,0.6)
\psline[linewidth=0.02cm](0.0,0.6)(1.1,0.6)
\psarc[linewidth=0.01](3.0,-1.0){0.4}{138.81407}{180.0}
\psarc[linewidth=0.01](1.5,-1.0){0.3}{0.0}{135.0}
\psarc[linewidth=0.01](3.9,1.0){0.3}{26.565052}{333.43494}
\psarc[linewidth=0.01](4.0,0.9){0.3}{26.565052}{333.43494}
\psarc[linewidth=0.01](4.1,0.8){0.3}{26.565052}{333.43494}
\psarc[linewidth=0.01](4.2,0.7){0.3}{26.565052}{333.43494}
\end{pspicture} 
}



\section{Comments on this thesis}
There Frans and Isaac,

%TODO
I incorporated most of the feedback except for
-the test on different datasets\\
(the dataset is not ready yet)\\
-large introduction\\
I elaberate a bit more then my prev version but I think you want more background
information.\\
I do this in a few chapters earlier which is not included in this document.\\
- other types of roofs?\\

\section{Improving the 3D building}
\subsection{Introduction}
%chain
In the previous chapter we extracted the building contour with the skyline
detector. The output was a set of 2D points and we collected this set for every
view of the building.  The aim of this chapter is to use this set of points to
improve a basic 3D model.
%TODO introduce 3d model
%TODO talk about infinite heigh walls of the 3d model

%situation
First of all the point cloud from the skyline detector included a lot of noise caused mostly
by occluding objects like tree's. How do we detect those outliers?
And if we have an outlier free point cloud how can we use this information to
improve the 3D model? How can a point be associated to a specific part of the
building and finaly improve the 3D model? 
These questions are addressed in this chapter.

%solution
The solution is made broadly in the following steps. First, the set of points is transfered to a set of
lines. Then each line segment is assigned to a wall of the building. After this 
the lines are projected to these assigned walls. 
These projections are used to estimate new heights of the building walls.
The 3D model is then improved by updating the walls according these heights. \\
 We will now elaborate on each step.


% TODO
% part of intro?:
% And if we know which data belongs to the building contour we could use the developed projection techniques from section %TODO
% to obtain parts of the building contour.
% The next question arises is, given this building contour parts, how do we
% improve the 3D model in a clean way?

%before we take these next steps we take one step back and go to the 2d images.
	%we saw that the skyline detector outputs a binary image where a white pixel is considered as highly from the skyline and therefor the building contour.
	%todo


% why not ransac?
\subsection{Extracting line segments}
\subsubsection{motivation/intro/chain to hough} %TODO

% Let us first define the input of the algorithm:
% \begin{itemize}
% 	\item a set of calibrated binary 2D images where white indicates a skyline pixel which has a high probability of being the building contour
% 	%TODO explain calibrated somewhere eerder in het report
% 	\item a rough 3D model extracted from an open street view database
% 	%TODO introduce the 3D model somewhere eerder in report
% \end{itemize}
%
% The output will be an updated 3D model, this output is developed in several steps:\\
% First some operation are done in 2D, the individual skyline pixels are grouped
% into line segments using an approach called the Hough transform. In the next
% step every line is heuristicly associated to (and projected on) a specific wall
% in 3D. The third step is to combine the projected line segments, which produces
% and estimate of the height of each building wall. In the last step these heights
% are used to improve the walls of the rough 3D model.

%why fit lines on 2d and not in 3d
%cheaper easier?

	To remove the outliers the process is put upside down: we detect the
	inliers and consider the remainder as outliers. But we first have to define an inlier.\\
	Lets take the contour of an average building, this is mostly formed by
	straight lines. We use this fact to simplify our problem:\\
	\textemph{Flat roof assumption}\\
	\textemph{We assume each building has a flat roof, implicating that each buildingwall
	has a straight upper contour}

	% todo example images
	If a set of skyline pixels lie on the same line, they form a straight line
	and therefor have a large probability to present a part of the building contour.
	These skyline pixels, that form a straight line, are therefor considered as our
	inliers. 
	If we have a method that extracts straight line segments, we can use these
	line segments to find parts of the building contour and finaly improve the 3D
	model. Next is explained how these straight line segments are extracted.
	% TODO what if a plain flys by? note in drawbacks of method

\subsubsection{Hough transform}
	A widely used method for extracting line segments is the the Hough transform
	(invented by P. Hough).  We regard this as a suitable method because it is
	used a lot for this problem. This is because it is unique in its low
	computational comlexity (compared to other (iterative) methods like RANSAC).
	%TODO reference
	We will explain this method briefly.
	In the Hough transform, a main idea is to consider the characteristics of a
	straight line not as its image points $(x1, y1)$, $(x2, y2)$, etc., but in
	terms of the parameters of the straight line formula $y = mx + b$. i.e., the
	slope parameter $m$ and the intercept parameter $b$.
	The input of a Hough transform is a binary image. In our case the output of 
	the skyline detector (chapter TODO).
	If a pixel is classified as a skyline pixel (a pixel that lies on the
	skyline according the skyline detector), the Hough transform increases
	a vote value for every valid line ($m$,$b$ pair) that crosses this
	particular pixel.  Lines ($m$, $b$ pairs) that receive a large amount of votes
	contain a large amount of skyline pixels.  
	Because the algorithm detects straight lines containing only skyline pixels it is
	most likely that it returns parts of the skyline and therefor the building contour. \\
	The Hough transform is implemented in \textemph{Matlab} and has some useful extra functions:\\
	The algorithm can optionally return the start- and endpoint of the found lines 
	which is very useful as it helps to associate which part of the building is described by the line.
	Furthermore it has the parameter \emph{FillGab} that specifies the distance
	between two line segments associated with the same $m$,$b$ pair. When the
	distance between the line segments is less then value specified, it merges
	the line segments into a single line segment. In our application this
	parameter in particular interest to merge lines that are interrupted by for
	example an occluding tree.

	%Because of occlusion the Houghlines could return two separate line segments
	%which is originally one line which is %onderbbbbbbbroken.
	\\
	Results of the Hough transform on the 2D output of the skyline detector are
	displayed and evaluated in the Result section.

\subsubsection{Heuristic Line-Wall determination}
% 	method below is very nice but it is outperformed by my ultragenius other
% 	method, so I could use it in the thesis but only as different test
% 	methods
%
% 	It would be straightforward to use the method of chapter %TODO
% 	Instead of a skyline pixel we could take the line segments endpoints and project it onto the building walls. The wall with the shortest distance will be assigned to the line segment.
% 
% 	%And to update the specific wall we first need to know with a high probability of being correct which wall the line segment presents
% 	But this method introduces a problem: some of the line segments have endpoints that lie at the corner of the building. These line segments could easily be associated with the neighboring wall. Because the 3D model is a rough estimate this could lead to bad results.
% 	In the corner case it is not clear to which wall the line segment belongs because both endpoints do not agree on the same wall. To solve this problem some heuristic methods are developed and tested. The following heuristic is both simple and effective.
% 	The heuristic uses the importance of the middle point of the line segment. This middle point has a low change of being on a building corner and the on average biggest change of being on the wall we are looking for.
% 	Therefor we discard the endpoints and use the middle point the endpoints to determine the right wall.
% 	As in the previous section %TODO
% 	this middle point is intersected with all planes spanned by the walls. The line segment is stored to the wall with the shortest distance.
% 	The output of this part of the algorithm is for every wall a bunch of associated line segments originated from different views.
% 
% 	%TODO example image
%TODO name different methods and put in table and test
% Some different methods
% method 1:
% take endpoints and project, con: endpoints don't agree
% see above tekst
% method 2:
% midle point
% method 3: 
% overlap

	% intro
	\paragraph{Introduction}
	The Hough transform of the previous section returned a set of 2D line
	segments.  If we could find a way to associate parts of the building with
	the 2D line segments, we can use this to improve our basic 3D model.
	This section explains how we associate the line segments with the most
	likely parts of the building. \\

	First the problem is analysed and together with that a few assumption are made.
	Then some heuristics are defined and finally the developed method is explained.

	\paragraph{Assumptions}
	% intro of assumptions
	We treat the parts of the building as individual walls and associate each
	line segment with a wall of the building that is most likely responsible for
	that line segment. 

	\emph{Unique wall assumption}:\\
	%motivation, straight lines, skyline detector
	\emph{We asume that the output of the Hough transform are line segments that
	each represent the upperside of the contour of a single wall of the building}

	%We assume that the output of the Hough transform, the 2D line segments this set
	%represents (parts of) the building contour. To be more precise we assume
	%that every line segment in the set represents (a part of) the upper side of
	%a specific wall of the building. 


	If a line segment is assumpted to represent a single wall then the
	projection to that wall should have a large line-wall overlap. To be more
	precise, lets define $l$ in $\mathbb{R}2$ as a line segment that is generated by the Hough
	transform.  If we project $l$ to the plane spanned by a certain wall $w$, we
	get a line $l_{proj_w}$ in $\mathbb{R}3$.  As we assumed, $l$ comes from the 
	contour of wall $w$. Its easy to see that $l_{proj_w}$
	should have a large overlap with $w$, and also should have a small overlap with
	the other walls.
	%see figure%TODO. create two figure's (2d and 3d) with a single houghline
	%(projected)
	
	\emph{Largest line-wall overlap assumption}:\\
	\emph{A line segment is originated from the wall with the largest overlap
	with the projected line segment.}\\

	Now we have defined the assumptions we explain the algorithm.

	\paragraph{Algorithm}
	The algorithm can be described broadly as follows:
	A line segment is projected to all walls and the amount of line-wall overlap is
	calculated. The wall with the largest overlap with the specific line
segment is classified as the most likely wall for that line segment.
	Next the line segments are projected to their most likely wall, the
	algorithm outputs this set of lines in $\mathbb{R}3$. 
	
	%\paragraph{Line wall overlap type}
	This line-wall overlap is calculated in different steps.
	First different types of overlap are explained. After the algorithm
	determines the \emph{overlap type}, the overlap amount is determined and
	normalized.

	$l_{proj_w}$ can overlap $w$ in four different scenarios:\\
		1) no overlap (see fig 10a)\\
		2) partial overlap (fig 10b)\\
		3) full overlap ($l_{proj_w}$ is included in $w$)(fig 10c)\\
		4) full overlap ($l_{proj_w}$ overextends $w$) (fig 10d)\\

	The type of overlap is defined exposing the endpoints of the line
	segments to an \emph{in polygon} test where the polygon represents a 
	wall of the building.
	%TODO REF MATLAB?
	%we use the Matlab build in polygon as in section (%TODO)

	The table below represents the types of overlap with the corresponding number of points
	that pass the \emph{in polygon} test and their possible line-wall overlap
	value.\\ 
	\begin{tabular}
	Type of line-wall overlap 			&	points in polygon 			& line-wall overlap \\
	no overlap					&	0					& 0		\\
	partial overlap 				&	1					& [0..1]	\\
	full line-wall overlap (included)		&	2					& 1		\\
	full line-wall overlap (overextended)		&  	0					& 1 		\\
	\end{tabular}
	\\

	If the point in polygon test returns 0, the line-wall overlap calculation
	is skipped and 0 is returned. The remaining overlap types (partial- and full
	line-wall) overlap are treated individually:\\

	% TODO latex draw
	% latex draw, show cut off line segments (different color)
	% extra dikke vector over de lijn DC
	% duidelijke pijl aan het eind van stippellijn
	% alpha of beta teken en daar naar verwijzen ipv vectors benoemen
	% TODO in figure overlap ratio percentages drawwen

	\paragraph{Partial overlap}
	Lets first consider the partial overlap type (Figure 10b), the \emph{in polygon} test
	returned 1, that means that one of the line segments endpoint lies in
	and one lies outside the wall.
	To calculate the amount of line-wall overlap, the line segment is cropped to the
	part that overlaps the wall and the length is measured. 
	The cropped line has two coordinates, first ofcourse the point that passed
	the \emp{in polygon} test and secondly the intersection of the line
	segment with one of the vertical wall sides.
	(Note that because we assume the walls to be of infinite height, the line
	segment partial overlapping line segment always intersects one of the
	vertical wallsides.)
	To determine which of the two vertical wallsides ($da$ or $cb$ from Figure 10b)
	 is crossed, we determine on which side the point that didn't lie in the polygon (v) lies.
	This is done by an angle comparison (as in section TODO).
	First, two groups of two vectors are defined: $dv$, $dc$ and $cw$, $cd$ see figure 10b.
	We measure the angles between the vectors and call them $\alpha$, and
	$\beta$. 
	Because one of the line segment endpoints lies outside
	the wall $\alpha$ or $\beta$ is obtuse, in this case $\alpha$ is obtuse.
	(Note that this only holds under the assumption that all wall sides are orthogonal)\\
	To be more precise: 
	\begin{itemize}
	\item if $\alpha$ is obtuse, the left vertical wallside $da$, is
	crossed. \\
	\item If $\beta$ is obtuse, the right vertical wallside $cb$, is
	crossed. \\
	\end{itemize}
	(The angles are acute or obtuse if the dot product of the vectors involved
	are respectively positive or negative. The advantage of this method is that
	it's simple and computational cheap.)
	The amount of line-wall overlap is easy calculated by cutting of the
	point where $l$ intersects the determined vertical wallside ($da$ or
	$cb$) and measuring its remaining length.

	\paragraph{Full or none overlap}
	Now lets consider the overlap types where the \emp{in polygon} test
	returned 0.
	As you can see in Figure 10a and 10d this resulted in either full or none overlap.
	Again we analyse the vector angles to determine the remaining overlap-type.
	If only one of the angles is obtuse, Figure 10a, with no points in the polygon 
	then the whole line segment lies outside the wall. An overlap value of zero
	is returned.\\
	Otherwise, if both angles $\alpha$ and $\beta$ are obtuse or acute (Figure 10d),
	both endpoints lie on a different side of the wall, and cross the wall in
	between. Full overlap is concluded here. 
	The amount of overlap is now calculated by measuring the length
	of the line segment which is cut down by his intersections with $da$ and
	$cb$. In this case this is the same as line $dc$, but its easy to see that
	this is not the case when the $vw$ is skew.





	
	Finally the line-wall overlap is normalized by the line segments length:\\
	$\alhpa_{l} = \fac{lwo}{|l|}$
	$\alpha_{l}$ is the normalized line-wall overlap, 
	$lwo$ is the unnormalized amount of line-wall overlap, 
	and ($|l|$) is the total length of the line sement.\\

	The intuition behind this is that line segments that are likely to
	present a wall not only have a large overlap but also have a small part
	that has no overlap. By calculating the relative overlap, both amount of overlap
	and -missing overlap is taken into account.\\

	The maximum of the normalized line-wall overlap is used to associate a
	line segment with his most likely wall.
	%TODO formula?
	\textemph{should I place a formula here? and if yes how do I denote this
	mathematically legal/correct}

	To summarize, the overlap type is defined by calculating the numbers of in
	polygon points and measuring some angles. Next the line segment is cut off
	depended on the overlap type and the line is normalized. A search for the
	maximum normalized line-wall overlap is used to determine the correct line-wall
	association.

	%TODO
	% example image where I project a line to every wall of the building
	% a table of wall overlap value's sorted on largeness
	% bedenken: hoezo wint niet altijd de achterste wall omdat er dan full overlap
	% is??



	% TODO:
	% make schema with 3 methods, and in one regel the summary of its technique
	
	% test with different techniques
	% make different dataset
	% hand anotated (pleonastisch zeg hehe) for ground truth
	% 1) project endpoints (and sometimes end up not agreeing wall)
	% 2) use midpoint of line
	% 3) use tjs algo (line wall overlap)

\subsubsection{Wall height estimation}
	%TODO CHAINING AGAIN
%	In the previous section we addressed the problem that the endpoints of a line segment may not agree on the wall.  We also introduced a method to associate a line segment with the right wall. 
  	In the previous section we associated the line segments with their most
	likely wall.
	In this section this information is used to estimate the height of the
	wall which is finally used to update the 3D model in section %TODO
	\\
	Now all line segments are associated with a certain wall we re-project the
	line segment from the different views on their associated wall. The re-projection is done by intersecting both endpoints of the line segment to the plane that is spanned by associated wall.
	Next the 3D intersection points are collected and averaged, this gives us an average of the midpoints of the projected line segments. We do this for every wall separately returning the average height of the line segments.
	These averages are then used as the new heights of the walls of the building.

\subsubsection{Improving the 3D model} 
	We made an assumption that a building consists of a flat roof (note that the walls may have different heights but the roof should be flat).
	In the previous section we calculated the new individual heights of the walls the building. 
	This is propagated to the 3D model by adjusting the location of the existing upper corner points of the walls. We copy the bottom left and -right corner points and add the estimated height from the previous section to its y-value.
	FOOTNOTE:Note that this method assumes that the walls are aligned on the y-axis, which is in our dataset the case.
	% TODO footnote: 
	%TODO iets zeggen over het ground plain, zie ook costins werk

	

\subsection{Results}
\fig{outputSkylineIm3-3.eps}{}{0.5}
Lets rehearse the output of the skyline detector in figure \ref{fig:outputSkylineIm3-3.eps}.
\fig{outputHoughlines2d.eps}{}{0.5}
\fig{outputHoughlines3d.eps}{}{0.8}
\fig{outputMutateBuilding.eps}{}{0.7}
Figure \ref{fig:outputHoughlines2d.eps} shows the top 3 longest Houghlines, the
endpoints are denoted with a black and blue cross. All three lines lie on the
building contour.  The left line covers only a part of the building wall. The
middle line covers the full wall. The left and middle line are connected. The
right line covers the wall until the tree occludes.\\

Figure \ref{fig:outputHoughlines3d.eps} displays the line segments (originated from
different views) projected onto their associated walls.  For a clear view we
only selected the lines that where associated with three specific walls of the building.  
The red cross in the middle of the line is representing the average of its endpoints.\\

Figure \ref{fig:outputMutateBuilding.eps} displays the augmented 3D model. The
corner points of the walls are adjusted according the calculated wall heights.
The green plane displays the augmented wall. The left and middle wall are extended
and the right wall is shortened.\\

%As can be seen from the different plane colors, the building walls are changed to their individual height.

\subsection{Discussion}
%TODO positief lullen over resultaat
%TODO (disadvantage unique wall asumption: line loopt door verschillende walls)
We will now discuss the results. As can be seen in figure
\ref{fig:outputHoughlines2d.eps} the left line segment doesn't cover the whole
building wall. This is caused by using strict parameters in the Hough transform
(like a small line thickness parameter).  If some ascending skyline pixels fall just outside
the Houghlines, a gap is created and the line segment is cut down at that point.
This is however not a big problem because the lines are long enough to produce a
good wall height estimate. Furthermore their are at least 5 other lines
(originated from different views) that
support this estimate for this wall.\\


\subsubsection{alternative roofs}
%TODO cons pros of the flat roof assumption
%TODO vet goed dat ik dus mijn algo different wallheights aan kan, promoten!
%TODO explain (earlyer) why flat roof?
	% to allign walls with the skyline of the skyline detector

We assumed flat roof
infinite height walls

Because of the flat roof assumption we didn't consider alternative rooftypes.
We now discuss what adaptations the system should require to handle alternative roofs.
In figure TODO, 6 different roofshapes are displayed.\\
%TODO insert figure
Because we assume that the roof images are taken from the ground, the skyline
detector will always detect the top of the building. In case of the flatroof
assumption this was also the top of the building walls.
In case of a alternative roof this is just the top of the building and something
else needs to be developed to find the building walls. Furthermore we want to
know which rooftype we are dealing with to generate the 3D model.\\
Some ideas about this are now proposed:\\
Use a object dector to detect doors, windows and dormers to estimate the
number of floors, the location of the wall-roof separation and the exclution of
some rooftypes (e.g. a dormer is never located on a flatroof).\\
Use the Hough transform to search for horizontal lines between the groundplane and the
heigh roofline to detect the wall-roof separation. Some buildings have a gutter,
because of this fact the number of horizontal lines on the wall-roof separation
will be larger which is useful.\\
Use gps and geografic information and a database of rooftypes with gps location
to classify the rooftype. The skyline detector detects the buildingheight, if we
could use predefined information about the ratio between the wallheight and
total height of the building, the wallheights could be estimated.\\
Assuming we determined the rooftype, buildingheight and wallheights, the 3D model could 
easy be generated. 
%For example the Gable, Gambrel and Hipped roof have in common that the heighest
%roofline  is in the middle of the building.
For the \emph{Gable} roof for example this will involve connecting the upperside of the
walls with the heigh roofline (returned by the skyline detector). For the other
rooftypes, the buildingheight and wallheight and a template structure of the
roof could be used to generate the 3D model.

% old middle point shizzle
% The left and middle line segment of figure \ref{fig:outputHoughlines2d.eps} are
% a good example of the corner problem. Both endpoints could easily be associated
% with the wrong wall (even if the rough 3D model is very accurate). Fortunately
% we use the middle point of the line segment to determine the correct wall. This
% works well as its 100\% accurate (for this dataset).
%TODO check text on old usage of e.g. middlepoints 



% midpoint heuristic
\subsection{Conclusion and Future work}
We now discuss some future work and conclude.  In this thesis little is discussed about the computational costs. This is because the computations are done efficiently (e.g. using matrix multiplications in Matlab) and offline, making the calculation process done in reasonable time. To make the application real time the next speedup would be useful.\\
To find the closest wall the middle point point of the line is now projected to all walls, it could be a significant speedup to reduce the set of walls to only the walls that are found at the endpoints. The downside is that it is slightly dangerous because it could be the case that both line segments endpoints could lie on a corner point making it possible that none of the endpoints refer to the correct wall.\\

As can be seen from figure TODO%TODO
%TODO fix MISSING FIGURE
two line segments appear on the same wall. This means they have a double influence on the average wall height which is unfair. A simple solution would be to add a normalization preprocess step so each view has only one wall height vote per wall. A more elegant solution would be to merge the two (or more) line segments to a single line segment. This could be achieved with an iterative Hough transform where the \emph{FillGap} parameter is increased in each iteration. For fig ?? %TODO 
%TODO why iterative?? why not big gab as param??
two iterations would be enough where the \emph{FillGap} parameter needs to be at least as big as the occluding tree in the second iteration.\\
To make the algorithm more generic the flat roof assumption could be stretched or even discarded.
Consider figure TODO %TODO schuin roof plaatje
it has a roof consisting of two planes which are not parallel with the facade of the building. This makes the problem of extracting the 3D model more complex but not 
infeasible. By developing a method for this it would be smart to make symmetry assumptions. The roof lies exactly in the middle of the building and it consists of two symmetric planes, this is useful information. In 
%TODO ref opzoeken
[REF] a polygon fit procedure is used where even dormers are recognized.\\

Furthermore it would be nice the fully discard the flat roof assumption. This will allow a building to have any shape, which is nice. The drawback is that a new method of outlier detection has to be developed. Object recognition could have a great deal in this. If one knows where for example an occluding object is located, then this could be used to filter the output of the skyline detector. This gives rise to a new problem that the 3D model has no augmentations at the position of occluding objects. Making sense of what would be behind the occluding object would be a interesting AI challenge and will incorporate pattern recognition, making use of repetitive structures and off course combining the multiple views to reveal as much information.\\

To conclude, we showed that a Houghline transform is a useful method to detect outliers and find prominent structure in the building contour. We introduced a heuristic to pair up line segments with their associated walls. This was used to produce new wall heights which where propagated to the 3D model.
Existing and novel AI computer vision techniques where powerful combined resulting in an accurate 3D model based on only a few calibrated 2D images. 


\subsection{References}
%TODO hough



% TODO
%TODO what are the mathematics
%TODO write something about complications and wat je er aan hebt
%use power of illustration, lots of example images! ask myself is there stil something left where I can add an illustration??
% read again and check level of detail, is it everywhere the same?
% do I do enough chaining?
% read again on other subjects in mind see how te wr thesis

%TODO spell check!!


\end{document}
