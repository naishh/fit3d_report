\section{Introduction}
When we humans look at an urban scene we immediately can tell which part
represents a building, a tree, a door, a window or a parked car.
Even if the scene suffers from high occlusion (e.g. a tree occluding the largest part
of a building) or extreme perspective distortion (a building seen from the
corners of your eye) we perform this task with a very high accuracy.
For a computer system however, this task is far from trivial.\\

Let us address the question that arises many times in Artificial Intelligence:
Why are we humans so good in this task? What can we learn from ourselves 
and how can we apply this on a computer system?\\

The most important reason of our excellent visual perception is that we combine 
a series of depth cues \cite{psy} (which enables us to experience depth) with
feature-matching (which enables us to classify objects).
One of the most important depth cue is binocular disparity.  We use two eyes and look at
the same scene from slightly different angles.  This makes it possible to
triangulate the distance to an object with a high degree of accuracy \cite{psy} \cite{hartley}.
Figure \ref{fig:bindisp.eps} illustrates this.\\ 
\fig{bindisp.eps}{Two cues that play a central role in depth perception. Source: \cite{psy}}{0.15}

\newpage
Furthermore we classify objects, according to a widely supported theory in
psychology, using feature-matching \cite{anderson} \cite{psy}. 
We do this by matching discriminative features of
an object to feature sets stored in our memory. In this theory 
a retinal image is passed on to a set of feature demons, which proces for example
horizontal/vertical lines or right angles in the image.  In a next level 
of processing, decision demons are activated if a combination of these features is detected.
An example of the perception of a letter R is illustrated in Figure
\ref{fig:demons.eps}.\\

\fig{demons.eps}{Matching observed features to feature sets already stored in
memory. Source: \cite{psy}}{0.16}.

These visual processes are extremely informative if we want to build a computer system
that acts accordingly.  This thesis is about our work of a system that adds semantics to an
urban scene inspired on the human brain.  \\

We use stereopsis to generate a 3D model of the building.  And feature-matching,
similar to the discussed model, is applied to detect skylines and windows where
we use descriptors based on edge features like straight lines and right angles.
Before we explain our methods let us first share the variety of applications 
that use semantical interpretation of urban scenes. 

\newpage
\subsection{Application examples}
\paragraph{3D City models} 
	Manual creation of 3D models is a time consuming and expensive procedure.
	Therefore semantic models are used for semi automatic 3D
	reconstruction/modelling.
	 %[Procedural Modeling of Buildings].  
	The semantic understanding is also used in 3D city models which are
	generated from aerial or satellite imagery.  The (doors and) windows are mapped to the detected 3D model to increase the level of detail \cite{Muller_procedural2}. 
	Some other applications can automatically extract a CAD-like model of
	the building surface.

\paragraph{Historical buildings documentation and deformation analysis}
	In some fields of research, historical buildings are documented.  The complex
	structures that are contained in the facades are recorded and reconstructed.
	Another field of research is the analysis of building deformation in areas
	containing old buildings \cite{deformation}.
	 Window detection provides information about the
	region of interest that could be tracked over time for an accurate
	deformation analysis.
	%[A SEMI-AUTOMATIC IMAGE-BASED MEASUREMENT SYSTEM]

\paragraph{Interactive 3D models}
	There are some virtual training applications that are designed for
	emergency response requiring interaction with a 3D model.  
	For the simulation to be realistic it is important to have a model that is
	of high visual quality and has sufficient semantic detail (i.e. contains
	windows).  This is also the case for a fly-through visualization of a street with
	buildings.
	Other applications that require semantic 3D models are virtual tourism,
	visual impact analysis, driving simulation and military simulation systems.
	\fig{p_simulation_people.eps}{Simulation environment}{0.3}

\paragraph{Augmented reality}
	Some mobile platforms apply augmented reality using facade and window
	detection to make an accurate overlay of the building. An example overlay is
	the same building but 200 years earlier.  Semantical information is used to
	not only identify a respective building, but also find his exact location in
	the image.  The accuracy and realistic level of the 3D model are vital for a
	successful simulation.  And because the applications are mobile, very fast
	building understanding algorithms are required.  Window detection plays an
	important role in these processes as the size and location of the windows
	supply an effective descriptor that can be used for robust and fast building
	identification.  Furthermore it provides an accurate alignment of the
	overlay.

\paragraph{Building recognition and urban planning}
	Building recognition is used in the field of urban planning where the
	semantic 3D models are used to provide important references to the city
	scenes from the street level.  Building recognition is done by using large
	image datasets where the buildings are mostly described by local information
	descriptors.  Some approaches try to describe the 3D building with laser
	range data. Some methods fuse the laser data with ground images. However,
	those generated 3D models are a mesh structure which do not make the facade
	structure explicit.  For a more accurate disambiguation, other types of
	contextual information are desired.  The semantical interpretation of the
	facade can provide this need.  In this context, window detection can be used
	as a strong discriminator.\\

We can conclude that semantic interpretation plays an important role in the
interpretation of urban scenes and is applied in a wide range of domains.  

\newpage
\subsection{Thesis outline}
The outline of this thesis is as follows:\\ 

We start with explaining basic computer vision techniques and the \emph{FIT3D toolbox} in Chapter 2.  
These techniques are the driving
force behind the algorithms used in both skyline detection and window detection.  
In Chapter 3 we explain a novel application of skyline detection: the detection
of building contours in urban scenes. Next, we use this result to
extract a 3D model of a building in Chapter 4.

In Chapter 5 we start a new topic: window detection. First we propose a window
detection method that operates on an unrectified facade. The second method uses
a rectified facade. We discuss and compare two window alignment and
classification methods.  We conclude in Chapter 6 and we finish with additional
results in the Appendices.\\

Many methods used in this thesis are independent from each other. Therefore we
choose to discuss the results, discussion and future research for each method
separately.  Also the chapters are independent from each other. Therefore, a
reader only interested in one particular topic may read only the associated
chapter while skipping the other chapters.



