% todo 
% be more clear about the projection, its the first time the reader sees it 



\section{Extracting the 3D building}
%todo plaatje van scene met een 3d model erin
%todo plaatje 2d model
\label{sec:generate3dModel}
% motivation
\subsection{Introduction}
In the previous chapter we explained our skyline detection algorithm which
extracted the skyline of a scene. The output is a set of 2D points which was  
collected for a sequence of images.
The aim of this chapter is to use this set of points together with an
 aerial 2D model of the building and the 3D pointcloud obtained by the FIT3D
 toolbox\cite{fit3d} (\ref{sec:prelimFIT3D}) to generate a 3D model of the
 building.


\paragraph{Research question}
%todo uitgebreider over fit3d linken 
Is it possible to use a set of (noisy) skyline points together with an aerial
2D model and a 3D pointcloud obtained by \emph{FIT3D toolbox\cite{fit3d}} to generate a 3D model of the building?


We present a stepwise solution.\\ 
First \emph{Openstreetmap} is used to obtain a 2D topview of the building (the
different parts of the 2D model represent the walls of the building). Next the
3D pointcloud obtained by the \emph{FIT3D toolbox\cite{fit3d}} is used to align this 2D
model in the scene.  After this the set of points returned by the skyline
detector is transfered to a set of lines. Then each line segment is assigned to
a part (wall) of the aligned 2D model.  After this the line segments are
projected to vertical planes spaned by the 2D model.  The result is used to
estimate the height values of the walls of the 2D model. The 2D model is
transformed according this height values to a 3D
model. We will now elaborate on each step.\\


\subsection{Method}
\subsubsection{Extracting the 2D model}
The basis of the generated 3D model is its ground-plane: a 2D model originated from
\emph{Openstreetmap}.
\fig{openstreetmap}{Openstreetmap with annotated buildings}{0.3}
\emph{Openstreetmap} (Figure \ref{fig:openstreetmap}) is a freely accessible 2D map generated by
users all over the world. It contains information about streets, building
contours, building functions, museums, etc.  We are interested in the building
contours therefor we take a snapshot of a particular area and extract this building
contour.  This is a set of ordered points where each point corresponds to a
corner of the building.  Next we link these points to line segments which
represent (the topview of) the walls of the building.

\subsubsection{Aligning the 2D model}
\fig{pc_3d.eps}{ 3D point cloud of the walls of the building}{0.5}
We want to align the 2D model extracted from \emph{Openstreetmap} in the scene at the right location with the right aspect ratios. 
From \emph{FIT3D\cite{fit3d}} we have the 3D point cloud of the building in world coordinates
(Figure \ref{fig:pc_3d.eps}).
The first challenge is to obtain a topview of the 3D point cloud.
How can we determine the direction of the top view? We want to project in the
direction that is most parallel to the walls and orthogonal to the ground-plane of the 2D model.

\paragraph{Gravity aligned walls assumption}
	\emph{The walls of the building are aligned in the opposite direction of the gravity
	which is orthogonal to the 2D basis from \textbf{Openstreetmap}}. This means
	we assume the images taken upright: the camera's $roll=0$ (Figure
	\ref{fig:cameraPitch.eps}).\\

Now we have defined the wall direction, we obtain the topview of the 3D point
cloud by discarding the y-dimension of the points.  Note that this is equivalent to a
projection to the x,z plane. The result is a set of 2D points that represent the
topview of the 3D point cloud (Figure \ref{fig:pc_topview_linefit.eps}).

We determine the walls by fitting line segments in the point cloud.  We
annotated these line segments manually.  (If the system needs to operate
automatically, RANSAC can be used to fit lines in this point cloud.)

\fig{pc_topview.eps}{The projected 3D point cloud of the walls of the
building}{0.4}
\fig{pc_topview_linefit.eps}{The top view building walls represented the fitted line
segments, M1}{0.5}
\fig{pc_topview2DModel.eps}{M2, the 2D model extracted from \emph{Openstreetmap}
aligned width the point cloud}{0.5}
\clearpage

The next step is to align the 2D \emph{Openstreetmap} model $M1$ with these line segments of the
projected pointcloud $M2$.  First the endpoints of the line segments, which
correspond to the wall corners, are extracted in both models.
Not that the walls of $M2$ that are located at the back of the building are often missing
because they are occluded by the front walls. We only consider the corners that
are present in both models.
Next the correspondences between these corners is annotated manually. 
This is used to generate a set of linear equations
which are solved in closed form \cite{hartley}. The result is a matrix $A$
which represents the rotation, translation and scaling that is needed for a
coordinate of $M1$ to be transformed to $M2$.
Finally $A$ is applied on all cornerpoints of $M1$ which results in an aligned 2D
model (Figure \ref{fig:pc_topview2DModel.eps}).

%affinetransform
%http://stackoverflow.com/questions/1856210/trying-to-derive-a-2d-transformation-matrix-using-only-the-images
%http://docs.oracle.com/javase/1.4.2/docs/api/java/awt/geom/AffineTransform.html


%todo convention matrix bold?
%------------------------------------------------------------------------
%todo example image of 3d model overlay
% of osgviewer screendpumps pakken en het erinplakken
% of building.osg in osgviewer plakken
% of in matlab de boel tegelijk plotten


%discuss disadvantage (skew Y assumption)
% see images in 
%  /media/Storage/scriptie/fit3d/results/anglebug
% formula of 3 coords of wall with an Y coord 



\subsubsection{Transfering the aligned 2D model to 3D}
Because the 2D model is based on aerial images it contains no
information regarding the height of each wall. 
In the next section we explain how we obtain the precise height values.\\

For the sake of presentation we use an average building height to generate a
rough estimate of the 3D model.  The 3D model is generated by taking 2D model
and extend it in the opposite gravity direction.  An example of the 3D model can
be seen in Figure \ref{fig:3dModel}.

\fig{3dModel}{An example of a basic 3D model, generated by extending a basis
(2D) model from \emph{Openstreetmap} to an average building height}{0.5}
%todo fit3d linken

%todo plaatje maken van aligened model: probleem plotBuilding is niet aligned
%met generate../align3dmodel



\subsubsection{Extracting line segments}
\label{extractinglinesegments}
	Because we want to estimate the height of the building walls of the 3D model we
	need to know how high the walls in the 2D images are.  To estimate this we
	first determine which part of the skyline is part of the building contour.
	Straight lines in the skyline area are likely to come from the building
	contour.  If we have a method that extracts straight line segments from the
	skyline, we can use these lines segments to estimate the height of the walls
	of the 3D model.  In this section we explain how we extracting this straight
	line segments.  \\

\paragraph{Assumptions}
	Many urban areas contain buildings with a flat roof. This makes the contour
	of the building is always formed by a set of straight line segments.
	Furthermore the contour of the building is always aligned with the upper side
	of a building wall.  
	If we assume a flat roof we can find the height of the building walls without
	having to concern for (complex) roof types.

	\subparagraph{Flat roof assumption}
	\emph{We assume each building has a flat roof, implicating that the building
	contour is aligned with the topside of a building wall.  The building walls
	may have different heights but the roof should be flat.}\\


\paragraph{Hough transform}
cutted

\subsubsection{Project the skyline to the 3D model}
\ref{sec:project}

	% intro
	The Hough transform of the previous section returned a set of 2D line
	segments which likely present parts of the building contour.  
	As we want to estimate the building wall heights we need to determine the wall
	of the building that is most likely responsible for that line segment.
	We can solve this problem by projecting the line segments to a specific
	part of the 3D model. To 
	This is done in three steps, first the camera is calibrated, next we
	project the line segments to the the building and finally we 
	determine the specific building part that is associate with a line segment.


	To project the line segments to the 3D model we need to know where the
	camera was positioned and heading when it took the photo (extrinsic
	parameters). Furthermore we need to know in what way this camera transformed
	the image (zoom factors, lens distortion etc.) (intrinsic parameters).
	This process is referred to as Camera Calibration and is explained in (
	\ref{sec:cameraCalibration})
	 
	\paragraph{From image point (2D) to possible points in scene (3D)} 

	What can we do if we computed the camera calibration parameters?
	The line segment that was returned by the Hough transform consists of two
	endpoints $v$ and $w$. These endpoints are in 2D but are recorded in a 3D
	scene and therefore present a 3D point in space. We don't know which point
	this is as for example we don't know the distance from the 3D point to the camera that took
	the picture. 
	However, because we calibrated the camera (\ref{sec:cameraCalibration}) we
	can reduce these possible points in 3D space to a line. Next we explain how
	we calculate this for one 2D image point (for example a line segment endpoint).\\

	We know:
	\begin{itemize}
		\item $\vec{x} = (x,y)$, the image point (in the camera coordinates
		(xyz))
		\item $\vec{x}_{h} = (x,y,1)'$, the homogeneous coordinate of the image point.
		\item $\vec{c}$ and $\vec{h}$, the camera's extrinsic parameters (the
		camera's center and heading in world coordinates (ijk))
		\item K, the cameras intrinsic parameters
		\item P, the projection from camera coordinates (xyz) to world
		coordinates (ijk). It contains implicitly the intrinsic and
		extrinsic parameters (the camera's center $\vec{c}$ and heading
		$\vec{h}$) and is applied to transfer the camera image points $\vec{x}$ (xyz) to world
		coordinates (ijk).
	\end{itemize}

	The two coordinates that span the line of possible points in 3D space are
	calculated as follows:
	\begin{itemize}
		\item $\vec{c}$, the location of the center of the camera in 
		world coordinates (ijk)
		%todo %(camera centers are annotated for every image)
		\item $\vec{x}_{ijk} = P K' \vec{x}_{h}$, the image point that lies on the retina of
		the camera expressed in world coordinates (ijk).\\
	\end{itemize}
	This is illustrated in Figure \ref{fig:coordinateSystemsCopy.eps}.
	\fig{coordinateSystemsCopy.eps}{The blue line spanned by the camera center $\vec{c}$ and the image point
	$\vec{x}$ tranfered to world coordinates represent the possible 3D points in
	space. $\vec{X}$ is a random possible point on the line.}{1}
	\clearpage

	%todo image
	%todo zee zisserman pagenumbers in feedbackmap

	%So the problem is boiled down in finding the Camera centers and viewing
	%directions and finding the
	%Calibration matrix.\\

	Using the two required coordinates we set up an equation of the
	line of possible points in 3D.  

	 \[ l = \textbf{c} + (\textbf{x}_{ijk}-\textbf{c})t, t \in \mathbb{R} \]

	for example if $t=100$ then the point in the real world lies at 100 times
		the distance from the camera center to its retina.
	In Figure \ref{fig:1cameraModel.eps} t is about 4 (for point M).

	Above calculations are done for each line segment endpoint
	line is spanned 
	Now we know which possible points in 3D a 2D point of the skyline presents,
	we can use this to find the corresponding wall.


\subsubsection{Associating line segments with building walls}
%todo I miss an important issue here, namely that I assume every wall to appear
%in equal size but this is not the fact, e.g. a projection of the same line on a
%different wall, that stands further away from the cc will appear bigger
%therefor the is not very 'eerlijk'
% say something about equal size assumption, where i throw away the dimension
% that is pointing from the camera cc
% solution: dichterbij heeft voorrang
	\paragraph{Building wall appearance assumption:}
	\emph{We assume that every straight line segment of the skyline represent (a part of) the upper side of a specific wall of the building.}
	Unfortunately we don't know which line is associated with which building
	wall. In this section we determine this association.

	First we prepare the 3D model. Next we project the line segments to all planes of the 3D building by
	taking their endpoints and using the technique of the previous section (\ref{sec:project})
	Finally we determine the most likely plane based on the largest line-wall overlap. 

	\paragraph{Preparing the 3D model}
	%The building is first divided into different walls.  Every wall of the building spans a plane. 
	%Intersections are then calculated between the lines and the planes of the building walls.\\
	The 3D building model consists of different walls. A wall is described by
	two ground coordinates, a height, and a direction.
	The height is based on an average building height, the direction is always the
	y-direction (see \emph{Gravity aligned walls assumption}).\\
	First we transform the walls into (infinite) planes.  This is done for two
	reasons: first this transformation is required to calculate the intersection
	properly. Second, because the 3D model is an estimate, the walls maybe just
	to small which could result in a missing intersection. \\


	\paragraph{Intersect with all walls}
	Now we have the building walls transformed to planes we take the endpoints of the
	lines and project them to all the planes of the building.  

	Each 2D endpoint has a line of possible 3D points which we calculated in the
	previous section. This was the line spanned by the camera center and the
	image point in world coordinates.
	This line is intersected with all planes of the building walls. Every 2D
	endpoint is now associated with multiple intersections resulting in 2 x
	$l$ x $w$ points in 3D (grouped by the line segments), 2 means
	\#endpoints of the line, $l$ is the number of lines and $w$ is the number of
	walls.\\

	We now calculated every possible projection to (/intersection with) every plane. 
	
	cut
