%TODO ground plane extraction together with skyline gives facade region

\section{Skyline detection}
\label{sec:skylinedetection}
 \subsection{Introduction}
If we take a regular image on which both sky and environment are present, there
is often a clear separation between them. This separation is called the
skyline. %oehhhhhhh  dat is echt masterlijk ouwe
The detection of this skyline has proven to be a very successful computer vision
application in a wide range of domains ranging from object detection\cite{Dust}, 
guiding micro air vehicles\cite{Guidedflight}, car localization, etc. 

In this research skyline detection is applied on different views of a scene to
estimate heights of facades of a 3D model. This is a novel application for
skyline detection.\\

The organization of this chapter is as follows: first we give a summary of
related work on skyline detection. Next we explain how we developed a new
robust skyline detection algorithm. Then we present and discuss some results
and, finally, conclusions are given.

\subsection{Related work}
Castano et al. \cite{Dust} present a clear introduction of different skyline
detection techniques. 

\paragraph{Detection of dust devils and clouds on Mars}
In \cite{Dust}, mars Exploration Rovers are used to detect clouds and dust devils on Mars.
Their approach is to first segment the sky from the ground and then determine if there are clouds in this region. The sky is detected by an innovative
algorithm that is similar to the one of Cozman et al. \cite{Rover}. 
This time the variation in intensity is used to discriminate the sky from the ground.
The algorithm uses a sliding window that slides from top to bottom. If looks for
an location where the intensity variation is high. This location is classified as a
skyline point. The sky is segmented by taking the area above these skyline
points. Next, this segmented sky is used for the detection of clouds and dust
devils.\\

This method looks like a very sophisticated one, as it is accurate and autonomous.
However, in our research we have a stable scene with sharp edges at the building
contour so this method would be an implementation overkill. \\


\paragraph{Horizon detection for Unmanned Air Vehicles}
In the domain \cite{Guidedflight} of unmanned vehicles, scientists detect the horizon to stabilize and control the
flight of Unmanned Air Vehicles.\\  
S.M. Ettinger et all \cite{Guidedflight} use a horizon detector that takes
advantage of the high altitude of the vehicle, in that way the horizon is
approximated to be a straight line. 
This straight line separates the image into sky and ground. They use color as
a measure of appearance and generate two color distributions: one for the sky
and one for the ground. They use the covariance and the eigen values of the
distributions to guide a bisection search for the best separation. The line that
best separates the two distributions is determined to be the skyline.\\

This work is not applicable for detecting a building contour as the straight
line assumption doesn't apply. But it needs to be mentioned that some ideas for
section \ref{fig:extractinglinesegments} are inspired by this method.

\paragraph{Planetary Rover localization}
Cozman et al. \cite{Rover} use skyline detection in planetary rovers to estimate 
their location. 
To recover the rover's position they match image structures with a given map
of the landscape (hills, roads, etc). One of the matching image structures they
use is the shape of the skyline.
A ground truth skyline model $m$ is obtained using a full 360 degree panorama of the scene.
Next, a matching function is applied to the skyline observations and $m$ to estimate
the rovers location, see Figure \ref{fig:rover-models.eps}. 

\fig{rover-models.eps}{By matching map $m$ to the observations $s_1$, $s_2$ and
$s_3$ the position of a planetary rover is estimated}{0.4}

The skyline is detected using the fact that at a large change in intensity
occurs at skyline points. This is obviously because the color changes from sky to ground.
For every column of the image a search is done for a high intensity change. The 
largest change is determined to be the skyline.\\

The advantage of their algorithm is the simplicity and effectiveness, this
could make their algorithm suitable for this project. A big drawback is that
they prefer speed over accuracy. To increase accuracy, the detector is part
of an interactive system where an operator refines the skyline. For our
application the skyline detector must operate without any user interaction.
This brings us to our research question.




\subsection{Method}
\paragraph{Research question}
Can we build a skyline algorithm that operates without any user interaction, is
simple, is fast, and yet accurate enough to provide a solid skyline that can be
used to estimate wall heights?

\subsubsection{Situation and assumptions}
As the Rover method \cite{Rover} is simple and effective we used it as a basis and 
build a custom algorithm with higher accuracy on top of that. 
\paragraph{Situation}
Before we present the method, we define the situation and make some
assumptions.\\

\paragraph{Definition: skyline in urban scene}
\emph{A skyline in an urban scene is a set of points of the size $w$ (where $w$ is the
width of the image) where each point describes the location of the
transition from the sky to an object (e.g. a building) which is connected to the
earth.}\\

How are we going to detect this sky-building transition point?\\ 
In general, the color of the sky is very different from the color of the
building. A color-based edge detector would be an intuitive decision as this
produces edges on regions where intense  color transitions appear. However, the
sky and the building itself also contains color transitions (caused by for
example clouds and windows). So how do we determine the right transition
(edge)?\\

One of the solutions is to increase the threshold of the edge detector. In this
way the detector will only return intense color transitions. Note that this will
only pay off if the building-sky transition is the biggest transition in the image. 
Its easy to see that this is a tricky assumption as other objects may contain
larger color transitions. Furthermore it would not be robust to a change in
the lightning conditions, influenced heavily by the weather.\\

To solve this problem we draw an assumption that is based on the
idea of \cite{Rover}. Instead of using the sharpest edge we take the most upper sharp
edge and classify this edge as the skyline.\\

\paragraph{Top sharp edge assumption}
\emph{The first sharp edge (seen from top to bottom) in the image 
represents the skyline.}

Having defined the situation and assumptions we now explain our algorithm.

\subsubsection{Related algorithm}
As our algorithm is based on a related algorithm presented in \cite{Rover},
this is in detail described first.

% nog meer woordjes vooraf?
%gaussian smooth (explain if reader is thumb)

The algorithm uses three main steps first it applies a smoothing preprocessing
step then it calculates the intensity gradient to find a big color transformation
and finally it searches for the highest transformation.

Because the related algorithm searches for strong edges a preprocessing step is
applied to remove all vague edges. The pre-processing consist of a sizable Gaussian
smoothing window that is applied on the input image. The size of the window size
is correlated to the amount of vague edges that are removed.

Next the smoothed image is sliced in \#$w$ pixel columns. Each column represents
the \#$h$ intensity values of the image (where $w$ and $h$ are the width and height of
the input image). 
These columns are transformed to their derivative, called the smoothed intensity gradient. The values
of this transformed column are high when a big change in color happens (e.g.
when an edge is detected) at that location on the image.\\

Next the system walks through the values of a column, starting from the top.
When it detects a value with a gradient higher then a certain threshold it
stores its y-position (the height) and continues to the next column. After the
position in each column of the highest sharp edge is determined the algorithm is
done. The result is a set of $y$ coordinates of length $w$, that represent the
skyline. 

\subsubsection{Improved algorithm}
Taking the smoothed intensity gradient is a computational cheap way to
detect edges. It also has a big disadvantage because it is not robust to vague edges
(they don't survive the threshold). It is not surprising that the algorithm in \cite{Rover}
was used in an interactive system where the user has to refine the result.\\

Our aim is to develop an autonomous skyline detector, the only user interaction
that we allow is to set some parameters of the system. Furthermore the vague
edges need to be detected if they are part of the skyline. We will now discuss
the adaptations that we developed with respect to the related algorithm.\\

The column based approach of the related algorithm seems to be very useful and is
therefore unchanged. To be robust to vague edges we explored and tested
edge detecting methods that are different then the smoothed intensity gradient
based method.\\

\label{sec:edgeDet}
The output of the different edge detection techniques was studied on an empirical
basis and the Canny edge detector \cite{Canny} was a clear winner. This is
probably because Canny is a more advanced edge detector:\\
It uses two thresholds, one to detect strong and one to detect weak edges. 
It starts with the strong threshold and when it finds an edge it calculates his
direction. This direction is used to search for weak edges that are connected
at one of the sides of the strong edge. In this way noisy weak edges are
discarded because they are not connected to a strong edge. Furthermore it
doesn't discard the vague edges that are desired.
In Table \ref{tab:edge} 
we list MATLAB\cite{matlab}'s built-in edge detectors together with the method explanation.  
In the section \ref{sec:ResultEdge} one can find the results of the different
edge detection methods.


\begin{table}[ht]
\caption{Different edge detectors explained, Source: MATLAB\cite{matlab} Documentation}
\label{tab:edge}
%note naar mijzelf altijd eerst caption dan label, dan en slechts dan gaat hte
%goed met de nummering
\begin{tabular}{|l|p{10cm}|}
	\hline
	Name & method\\
	\hline
	\hline
	Sobel					& The Sobel method finds edges using the Sobel
	approximation to the derivative. It returns edges at those points where the
	gradient of the image is maximum.\\
	\hline
	Prewitt					& The Prewitt method finds edges using the Prewitt
	approximation to the derivative. It returns edges at those points where the
	gradient of the image is maximum.\\
	\hline
	Roberts					& The Roberts method finds edges using the Roberts
	approximation to the derivative. It returns edges at those points where the
	gradient of the image is maximum.\\
	\hline
	zero-cross				& The zero-cross method finds edges by looking for zero
	crossings after filtering the image with a filter that has to be specified.\\
	\hline
	Laplacian				& The Laplacian of Gaussian method finds edges by
	looking for zero crossings after filtering the image with a Laplacian of Gaussian
	filter.\\
	\hline
	Canny					& The Canny method finds edges by looking for local
	maxima of the gradient of the image. The gradient is calculated using the derivative of
	a Gaussian filter. The method uses two thresholds, to detect strong and weak
	edges, and includes the weak edges in the output only if they are connected to
	strong edges. This method is therefore less likely than the others to be fooled
	by noise, and more likely to detect true weak edges.\\
	\hline
\end{tabular}
\end{table}
We classify Canny as the most robust edge detector, and use it for the skyline detection
algorithm: the Canny edge detector outputs a binary image, therefore the column inlier
threshold is set to 1, which means that it finds the first pixel that is white. 
This is, as in the related algorithm, done from top to bottom for every column in
the image.\\
Because we know we are looking for sharp edges, we improved the algorithm by
introducing two preprocessing steps. First the contrast of the image is
increased, this makes sharp edges stand out more. Secondly the image undertakes
an extra Gaussian smoothing, this removes a large part of the noise. 

The system now has several parameters which have to be set manually by the user:
\begin{itemize}
	% officially i don't do this contrast thing ghehe, whoepsie daisy fooling the
	% reader
	\item Contrast
	\item Window size of Gaussian smoothing 
	\item Edge detector threshold
\end{itemize}

If the user introduces a new dataset these parameters need to be configured
as the image quality and lightning condition are scene depended.


\subsection{Results}
\subsubsection{Edge detection}
\label{sec:ResultEdge}
\fig{e_floriande_canny_050.eps}{Edge detection results. Method: Canny}{0.45}
The edge detection results of the other methods can be found in the appendix
(\ref{app:edge}).
\clearpage


\subsubsection{Skyline detection}
\paragraph{Datasets}
The skyline detection algorithm was applied on three datasets. 

\begin{table}[ht]
\caption{Dataset properties}
\begin{tabular}{|l||l|l|l|}
\hline
Name 	& Resolution 	& Source	& Location\\
\hline
\hline
Floriande & 1728x1152px  & FIT3D \cite{FIT3D}  	& Unknown\\
\hline
Bram	 & 3072x2304px  & Author					& Amsterdam, 'Postjesweg' west side\\
\hline
Folkert  & 3072x2304px  & Author					& Amsterdam, 'Postjesweg' east side\\
%\hline
%Anne	& 3072x2304px  & Author					& Amsterdam, 'Van Spilbergenstraat'\\
\hline
\end{tabular}
\end{table}

% The output of the skyline detector on the \emph{Floriande}
% dataset \cite{FIT3D} can be seen in Figure \ref{fig:outputSkylineIm3-3.eps}.
% %todo weg:
% We show the effect of different thresholds of the edge detector on the
% \emph{Anne} dataset (Figure \ref{fig:outputSkylineSpil-Im1-thresh070.eps})
% and the 
% \emph{Bram} dataset (Figure \ref{fig:outputSkylineSpil-Im13-thresh030.eps}). 
\newpage
\fig{outputSkylineIm3-3.eps}{The output of the skyline detector on the \emph{Floriande} dataset. The skyline elements are marked red.}{0.45}
\fig{outputSkylineSpil-Im29.eps}{The output of the skyline detector on the \emph{Bram} dataset. The skyline elements are marked red.}{0.3}


%\fig{outputSkylineSpil-Im1-thresh070.eps}{The output of the skyline detector with a too high threshold (0.70)}{0.3}
\fig{outputSkylineSpil-Im13-thresh030.eps}{The output of the skyline detector on the \emph{Folkert} dataset: a scene which violates the top sharp edge assumption. The hanging streetlight causes the detection of a sharp edge above the building. This results in a damaged skyline.}{0.3}
\clearpage

\subsection{Discussion}  % (What do my results mean to me and why)
Consider Figure \ref{fig:outputSkylineIm3-3.eps}, the largest part of the
building edge is detected. This is a good result, given the algorithm
operates without any user interaction.\\

We assumed that the first sharp edge (seen from top to bottom) in the image 
represents the skyline. We showed in Figure \ref{fig:outputSkylineSpil-Im13-thresh030.eps}
that the first sharp edge is not always the skyline.
This holds for more scenes: e.g. Amsterdam contains a large amount of
hanging street lights.  Furthermore, other sharp edged objects that appear above
the building, e.g. tree's or even an aircraft, will also produce a scene that
violates the top sharp edge assumption.  Therefore it would be nice to relax the or discard the first sharp edge assumption.
This implies that we have to extend the column based approach which is done
theoretically and described in Future research (\ref{sec:skylinefut}).

\subsection{Conclusion}
Let's answer our research question.
\emph{Can we build a skyline algorithm that operates without any user interaction, is
simple, is fast, and yet accurate enough to provide a solid skyline that can be
used to estimate wall heights?}\\

Beside some scene dependent parameters (like the threshold of the skyline) the
system works without any user interaction. No manual refinement step is needed
because the algorithm is robust and accurate enough to provide a base for the
next module in the system. Furthermore the algorithm is simple and has a low
complexity.\\

It is interesting to point out that the skyline detector is a stand alone method
and it can be optimized individually without any knowledge of the other modules
of this project.\\

Because the top sharp edge assumption closes the door for a large amount of
scenes, an alternative is desired. We designed a concept that relaxes this
assumption which is shared next.

\subsection{Future research}
\label{sec:skylinefut}
% \subsubsection{Automatic thresholding}
% As the threshold that decides whether an edge is strong enough to represent the
% skyline is manual and scene dependent. Therefore a method for automatic
% thresholding is desired. There exist many studies on this topic, most of the
% methods are based on the statistical analysis of the image. Detailed literature
% research needs to be done and an implementation must be made to provides a value
% for the threshold. If this is done the system will operate 100\% automatic.

\subsubsection{Hypothesis based skyline detection}
\fig{folkert_edgeHypothesis.eps}{Three top sharp edges of the \emph{Folkert}
dataset are highlighted. For the highlighted column the skyline happens to be the
3rd top sharp edge.}{0.4}
The first top sharp edge in Figure \ref{fig:outputSkylineSpil-Im13-thresh030.eps}
is on a large area a hanging street light instead of the skyline.
If we take a look at the edge image in Figure
\ref{fig:folkert_edgeHypothesis.eps} we observe that the skyline in this area is the second or third
sharp edge.
Let's relax the first top sharp assumption to an assumption where the skyline is
part of the first $n$ sharp edges (seen from top) with for example $n=3$.
The scene in Figure \ref{fig:outputSkylineSpil-Im13-thresh030.eps} now agrees with
this assumption.\\
The next challenge is to do detect the skyline properly on the entire image.
The existing column based approach could be used to generate $n$ hypotheses and we can build
an algorithm on top of that to classify which hypothesis is right (i.e. which edge
presents the skyline).

The hypothesis classifier must gather additional information. We could
discriminate the hypothesis for example by texture, color distributions or height
variation. We discuss the last two.

\paragraph{Color based skyline classification}
The buildings color differs from the sky color. Furthermore,
as a function of the horizontal location (x-axis), the color in both sky and
building only changes slowly.\\

One could extract the color distribution of the color in a certain area above
and under the skyline, let's call these A and U. \\
A and U should 1) have a significant difference (local) and 2) they should not vary much from 
other positively classified skyline points (global).\\

The global color distribution could be calculated by taking the mean of the
color distributions at previously detected skyline points.  Both conditions
(local and global) could have a weight which would be a parameter of the
system.\\

Let's test this conceptual algorithm on the scene in Figure
\ref{fig:outputSkylineSpil-Im13-thresh030.eps}.  We initialize the algorithm at
an interesting location which is highlighted in the figure.\\
The first (top) highlighted sharp edge doesn't have a large local difference in color distribution
above and under the skyline. The color above and under the position are mostly
white. Because the first condition fails and the second condition can't be
checked as no global color distribution is stored yet, the algorithm continues
with the next edge.\\
For this edge the same holds.
The third edge, however, succeeds because it has a large local color difference.
Therefore the algorithm classify it as a skyline point.
Furthermore it stores his color distribution to compare following skyline points.
Next the algorithm takes for example one x
location to the right.  It will again agree on the third edge on the same terms.
This time it rejected the outliers (first and second edge) with additional
because their color distributions differ to much from the color
distribution of the previously detected skyline point.\\

The expected output of the skyline detector using hypothesis based on color is
displayed in Figure \ref{fig:outputSkylineSpil-Im13-thresh070.eps}). 
\fig{outputSkylineSpil-Im13-thresh070.eps}{The expected output of the skyline
detector using hypothesis based on color}{0.35}
\clearpage

\paragraph{Height variation based skyline classification}
Let's zoom in to an image of the \emph{Floriande} dataset, see Figure \ref{fig:outputSkylineIm3-3-zoom.eps}.
We observe that many outlying skyline points are located at the tree.  The algorithm based on the
first $n$ sharp edges wouldn't be robust because the tree produces a too large
amount of edges. Therefore an alternative classification is desired.\\

The skyline points on the tree have a large height variation in common.
This could be used to isolate this area from the skyline.

Once areas that have a large variation of height are discarded we could connect
the positive classified skyline parts to fill the gap, see Figure
\ref{fig:outputSkylineIm3-3-zoom-con.eps}.\\

Note that we used height variation instead of height difference for a reason.  A
large height difference with a neighboring skyline point is allowed because the
building contour may contains large steps in height (e.g. at the left side of
Figure \ref{fig:outputSkylineIm3-3-zoom.eps} the skyline suddenly drops in
height).\\

We showed some examples of simple classifiers. Note that there is no limitation
to the approach of the classifier because it can be developed individually using
the existing column based method as its hypothesis generator.

\newpage
\fig{outputSkylineIm3-3-zoom.eps}{Zoomed image of the \emph{Floriande} dataset.
The height variation is large on the tree area.}{1}
\fig{outputSkylineIm3-3-zoom-con.eps}{The green lines connects the positively
classified skyline parts at isolated areas where the height variation is too
high}{1}
\clearpage




