%TODO ground plane extraction together with skyline gives facade region

\section{Skyline detection}
\label{sec:skylinedetection}
 \subsection{Introduction}
If we take a regular image on which both sky and earth are present, there
is often a clear separation between them. This separation is called the
skyline. %oehhhhhhh  dat is echt masterlijk ouwe
The detection of this skyline has proven to be a very successful computer vision
application in a wide range of domains ranging from object detection, 
guiding flights, car localization, etc. In this project it is used at urban
images to provide a contour of a building.  The contour will be used to
provide 3D information about the scene. This is a novel way of using skyline
detection.\\
For our application the skyline detector must be accurate, robust and must
operate without any user interaction. This makes it different from existing
skyline techniques (e.g. \cite{Dust},\cite{Guidedflight},\cite{Rover}).\\
The organization of this chapter is as follows:  First we give a summary of
related work on skyline detection.  Next we explain how we developed a new
robust skyline detection algorithm.  Then we present and discuss some results
and, finally, conclusions are given.

\subsubsection{Related work}
Castano et al. \cite{Dust} present a clear introduction of different skyline
detection techniques. 

\paragraph{Detection of dust devils and clouds on Mars}
In \cite{Dust}, mars Exploration Rovers are used to detect clouds and dust devils on Mars.
Their approach is to first identify the sky and then determine if there are
clouds in the region segmented as sky. The sky is detected by an innovative
algorithm that consists of three steps.  First they place seeds in a sliding
window whenever the homogeneity of the window is high. Then they grow this seeds
in the direction of edges which are estimated using a Sobel edge detector.
Finally each pixel located above the grew seeds is classified as sky.\\

Of the discussed methods so far, this seed growing method looks like the most sophisticated one, as
it is accurate and autonomous. However, we have a stable scene with sharp edges
at the building contour so this method would be an implementation overkill.  


\paragraph{Horizon detection for Unmanned Air Vehicles}
In this domain \cite{Guidedflight}, scientists detect the horizon to stabilize and control the
flight of Unmanned Air Vehicles.\\  
S.M. Ettinger et all \cite{Guidedflight} use a horizon detector that takes
advantage of the high altitude of the vehicle, in that way the horizon is
approximated to be a straight line.  
This straight line separates the image into sky and ground. They use color as
a measure of appearance and generate two color distributions: one for the sky
and one for the ground. They use the covariance and the eigen values of the
distributions to guide a bisection search for the best separation. The line that
best separates the two distributions is determined to be the skyline.\\

This work is not applicable for detecting a building contour as the straight
line assumption doesn't work.  But it needs to be mentioned that some ideas for
section \ref{extractinglinesegments} are created because the building has walls
that have straight lines, an assumption is made about partially straight lines.

\paragraph{Planetary Rover localization}
Cozman et al. \cite{Rover} use skyline detection in planetary rovers to estimate 
their location.  
To recover the rover's position they match image structures with a given map
of the landscape (hills, roads, etc) and align both images.
The matching process was first based on feature matching. In an improved version
the matching process was done by searching for correspondences among dense
structures in the image and on the given map, so called signal based matching.\\
The advantage of their algorithm is the simplicity and effectiveness, this
could make their algorithm suitable for this project.  A big drawback is that
they prefer speed over accuracy.  To increase accuracy, the detector is part
of an interactive system where an operator refines the skyline.  For our
application the skyline detector must operate without any user interaction.
Furthermore it has to be robust and accurate because it provides a basis for
the extraction of straight lines which offer an estimation of the buildingwall
heights.\\
We decided to use the Rover method \cite{Rover} as a basis and 
build a custom algorithm with higher accuracy on top of that. This is explained
in the next section.




\subsection{Method} % the algorithm, maar Isaac vindt dit fijner
\subsubsection{Situation and assumptions}
Before we present the method let's define the situation and make some
assumptions.\\

\textbf{\emph{Definition: skyline in urban scene}}\\
\emph{A skyline in an urban scene is a set of points of the size $w$ (where $w$ is the
width of the image) where each point describes the location of the
transition from the sky to an object (e.g. a building) which is connected to the
earth.}

%motivate assumption
The question is: how are we going to detect the sky-building
transition point?\\ 
In general, the color of the sky is very different than the
color of the building. The use of a color-based edge detector would be an
intuitive decision.\\
However, the sky and the building itself also contains edges (caused by for example
clouds and windows). So how do we determine the right edge?
The number of possible edges could be decreased by thresholding the intensity of
the edge but it would still be a difficult task to determine the right edge.
Furthermore the algorithm would not be robust to a change in
the lightning conditions, influenced heavily by the weather.\\

To solve this problem we draw an assumption that is based on the
idea of \cite{Rover}. Instead of using the sharpest edge we take the most upper sharp
edge and classify this edge as the skyline.\\

\textbf{\emph{Top sharp edge assumption}}\\
\emph{The first sharp edge (seen from top to bottom) in the image 
represents the skyline.}

\subsubsection{Related algorithm}
To put our work in context, we first describe a related skyline detection algorithm as presented in \cite{Rover}.\\

% nog meer woordjes vooraf?
%gaussian smooth (explain if reader is thumb)
To increase the difference between sharp and vague edges, and to let sharp edges
stand out more and vague edges disappear, the images are converted to Gaussian
smoothed images.  The smoothed image is first divided in \#$w$ columns.  Next,
each column produces a new column that stores its vertical derivatives. This is
called the smoothed intensity gradient.  The values of this column are high when
a big change in color happens (e.g. an edge is detected) at that location on the
image. 
The system walks through the values of a column, starting from the top.  When it
detects a pixel with a gradient higher then a certain threshold it stores its
y-value (the location of the highest sharp edge of that column) and continues
to the next column.  The result is a set of $y$ coordinates of length $w$, that
represent the skyline. 

\subsubsection{Improved algorithm}
Taking the smoothed intensity gradient is the most basic method of edge
detection and has the disadvantage that it is not robust to more vague edges. It
is not surprising that the algorithm in \cite{Rover}
was used in an interactive system where the user has to refine the result.\\

Our aim is to develop a autonomous skyline detector, the only user interaction
that we allow is to provide the system some parameters. We will now discuss
the adaptations that we developed with respect to the related algorithm.\\

The column based approach of the related algorithm seems to be very useful and is
therefore unchanged.  The related algorithm uses the smoothed intensity gradient
as a method to detect edges. 
Because of the accuracy disadvantage of this method we took another approach in
detecting edges. We tested different edge detecting types. 

The output of the different edge detection techniques was studied on an empirical
basis and the Canny edge detector \cite{Canny} came with the most promising results. This is
probably because Canny is a more advanced edge detector.  It uses two
thresholds, one to detect strong and one to detect weak edges. It includes the weak edges in the
output, but only if they are connected to strong edges. In Table \ref{tab:edge} %ref
we list Matlab's build in edge detectors together with the method explanation.

\begin{table}[ht]
\caption{Different edge detectors explained}
\label{tab:edge}
%note naar mijzelf altijd eerst caption dan label, dan en slechts dan gaat hte
%goed met de nummering
\begin{tabular}{|l|p{10cm}|}
	\hline
	Edge detecting type		& method\\
	\hline
	\hline
	Sobel					& The Sobel method finds edges using the Sobel
	approximation to the derivative. It returns edges at those points where the
	gradient of the image is maximum.\\
	\hline
	Prewitt					& The Prewitt method finds edges using the Prewitt
	approximation to the derivative. It returns edges at those points where the
	gradient of the image is maximum.\\
	\hline
	Roberts					& The Roberts method finds edges using the Roberts
	approximation to the derivative. It returns edges at those points where the
	gradient of the image is maximum.\\
	\hline
	Laplacian				& The Laplacian of Gaussian method finds edges by
	looking for zero crossings after filtering the image with a Laplacian of Gaussian
	filter.\\
	\hline
	zero-cross				& The zero-cross method finds edges by looking for zero
	crossings after filtering the image with a filter you specify.\\
	\hline
	Canny					& The Canny method finds edges by looking for local
	maxima of the gradient of the image. The gradient is calculated using the derivative of
	a Gaussian filter. The method uses two thresholds, to detect strong and weak
	edges, and includes the weak edges in the output only if they are connected to
	strong edges. This method is therefore less likely than the others to be fooled
	by noise, and more likely to detect true weak edges.\\
	\hline
\end{tabular}
\end{table}

Because the optimal edge detector type can be scene depended, it can be set
by the user as a parameter in our functions.\\

The Canny edge detector outputs a binary image, therefore the column inlier
threshold is set to 1, which means that it finds the first pixel that is white. 
This is, as in the related algorithm, done from top to bottom for every column in
the image.\\

Because we know we are looking for sharp edges we improved the algorithm by
introducing two preprocessing steps. First the contrast of the image is
increased, this makes sharp edges stand out more.  Secondly the image undertakes
an extra Gaussian blur, this removes a large part of the noise. Note that
depending on the edge detector type this could mean that the image is blurred
twice.\\

The system now has several parameters which have to be set manually by the user:
\begin{itemize}
	\item Contrast,
	% officially i don't do this contrast thing ghehe, whoepsie daisy fooling the
	% reader
	\item Intensity (window size) of Gaussian blur,
	\item Edge detector threshold.
\end{itemize}

If the user introduces a new dataset these parameters need to be configured
as the image quality and lightning condition are scene depended.


\subsection{Results}
Two different datasets are used. \\
The first dataset is the \emph{Floriande} dataset, which is included in the
Fit3d toolbox \cite{Fit3d}.  The dataset consists of eight images with resolution 1728x1152px.\\
The second dataset is named the \emph{Spil} dataset and it contains 40 images
with resolution 3072x2304px.\\
%bijzaken:
%the photos are taken of buildings near the street called 'van Spilbergenstraat, Amsterdam'.
%the images contain radial distortion, for the skyline detector this didn't seem to rise problems. The images are undistorted in the next module.

The output of the edge detector and skyline detector on the \emph{Floriande}
dataset \cite{Fit3d} can be seen in Figure \ref{fig:outputskylineFloriande}
We emphasize the effect of different thresholds of the edge detector on the
\emph{Spil} dataset in Figure \ref{fig:outputskylineSpil} and Figure
\ref{fig:outputSkylineSpil-Im1-thresh070}.

\pagebreak
\figs{outputskylineFloriande}{outputSkylineIm3-2.eps}{outputSkylineIm3-3.eps}{The
output of the edge detector and the skyline detector.}{The output of the edge
detector}{The output of the skyline detector. The skyline elements are marked
red}{14cm}{14cm}

\pagebreak
\figs{outputskylineSpil}{outputSkylineSpil-Im13-thresh030.eps}{outputSkylineSpil-Im13-thresh070.eps}{The
skyline detector on two different thresholds}{Because of the streetlight, a
large part of the building is not detected. Threshold=0.3}{The desired part of
the building is detected.  Threshhold=0.7}{14cm}{14cm}

\pagebreak
\fig{outputSkylineSpil-Im1-thresh070}{The output of the skyline detector with a
too high threshold (0.70)}{0.3}

\subsection{Discussion}  % (What do my results mean to me and why)
Consider Figure \ref{fig:outputskylineFloriande}, the largest part of the
building edge is detected. This is a desired result, given the algorithm
operates without any user interaction.\\
The system assumes that the first sharp edge (seen from top to bottom) is always
the building contour. This is why not every skyline element is placed on the building
contour but placed on, for example, a streetlight or a tree. We define them
as outliers. Other sharp edged objects that appear above the building,
for example an aircraft, will also turn into outliers.  This is a disadvantage of the
	column based method.\\
However, not every object above the building becomes an outlier, as can be seen in Figure
\ref{fig:outputskylineSpil} a change in the threshold parameter of the edge
detector can erase tough outliers. 
In Figure \ref{fig:outputSkylineSpil-Im1-thresh070} the risk of using a to high
threshold is shown. Although increasing the threshold to 0.7 removed the
streetlight outliers in, the results on this scene are very bad.\\

We decided to keep the threshold low and developed a seperate module to remove the outliers. It is not realistic to
assume full absence of sharp objects above the building, therefore we don't.
Furthermore this the part where we can add some artificial intelligence. This is
described in the next section.  

%TODO in kader discussion plaatsen
% In other systems where the skyline is detected in the context of a horizon like context.
% It isn't possible to keep track of the change in the skyline detector as the building has radical changes


\subsection{Conclusion and Future work}
A detailed research on related work research was done.
We introduced a novel application of skyline detection: the extraction of a
building contour. We build an algorithm on top of a successful existing
algorithm.  The algorithm doesn't depend on human intervention and is robust and
accurate enough to provide a base for the next module in the system.\\
It is interesting to denote that the skyline detector is a stand alone method and
can be optimized individually without any knowledge of the other modules of the
project.\\

Although the outlier removal procedure is done in a separate module, it would be
interesting (future work) to develop a skyline detector which is more robust to
outliers.  Most of the related work is based on detecting parts that are
classified as sky and parts that are classified as ground. The idea of detecting
the sky and ground could be replaced by detecting the sky and a building. The
distinctive textures of the buildings (repeating bricks) could be of great use
for the classification.  After that, a rough building contour could be estimated
	by using the highest building pixel for every column. In this neighborhood,
	detailed edge detection could be done. In this way the outliers (e.g. the
	streetlight and the tree) are filtered and no secondary outlier removal
	procedure is needed.




