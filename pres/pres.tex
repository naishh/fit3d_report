%todo opmaak
%todo print een documentje met whiteboard
%todo oefenen op eigen whiteboard

\documentclass{beamer}
\usetheme[compress]{Dresden}
\setbeamertemplate{navigation symbols}{} 

\include{commands}



%% notes: say welcome to my master thesis' defence
%\title{\LARGE \sc{Semantic annotation of urban scenes:}\\Skyline and window detection}
\title{\sc{Semantic annotation of urban scenes:}\\Skyline and window detection}
\subtitle{Speaker: Tjerk Kostelijk}
\author{Supervisors: \\Isaac Esteban\\Prof. dr ir Frans C. A. Groen}
\date{\today}


\begin{document}


%Committee:
%Prof. dr ir Frans C. A. Groen
%dr. P.H. Rodenburg
%dr. Arnoud Visser


\frame{\titlepage}

%\section[Outline]{}
%\frame{\tableofcontents}

% highlightoutline
\AtBeginSection[]
{
 \begin{frame}
  \frametitle{Outline}
  \small
  \tableofcontents[currentsection,hideothersubsections]
  \normalsize
 \end{frame}
}


\section{Introduction}
	%todo subsections

%-------------------------------------------------------------------
\frame
{
	\frametitle{Experiment}
	% blank dia
	%notes:
	%this is for a little warming up
	%and to answer the question why I did my research
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Experiment}
	%todo 1 sec
	\fig{floriande_back.eps}{420px}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Did you see?}
	%todo Yes en No op bord schrijven
	\begin{itemize}
		\item  <+-| alert@+> building
		\item  <+-| alert@+> tree
		\item  <+-| alert@+> bicycle
		%todo spellcheck
		\item  <+-| alert@+> street lamb
		\item  <+-| alert@+> red car
		\item  <+-| alert@+> blue car
		\item  <+-| alert@+> brand of the car?
		% blank dia
	\end{itemize}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Experiment}
	% blank dia
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Experiment}
	\fig{floriande_back.eps}{420px}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Q}
	\begin{itemize}
	\item  <+-| alert@+> Why are we so good at object/depth recognition?
	\item  <+-| alert@+> How can we apply vision to a computer system?
		\begin{itemize}
			\item  <+-| alert@+> {\textit{Computer Vision}}
			% this is the domain which interest me the most and on which I did my research
		\end{itemize}
	\end{itemize}
	%These are two questions that keeps us AI people bussy
	% I will answer the first one shortley and the rest of the presentation is about
	% the second question
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Outline}
	%todo print toc
	% -human perception
	% -skyline detection
	% -3d building reconstruction
	% -window detection
	 
	%todo think of transition
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Human perception}
	% lets talk about how you perceived the scene of the building
	\begin{itemize}
	\item  <+-| alert@+> depth cue, binocular disparity
	% vingertest
	% everybody raise your index finger, 
	% now close your left eye and switch to see your finger hopping
	% do the same with your finger further away
	% the displacement is smaller

	%We use two eyes and look at the sam scene from slightly diffeent angles
	%We perceive two different images, if an object appears close the differenc
	%displacement difference between the images is high
	%this makes it possible to triangulate the distance to an abject with a high
	%degree of accuracy

	\item  <+-| alert@+> Classify objects: feature detection
		\begin{itemize}
			\item  <+-| alert@+> straight lines
			\item  <+-| alert@+> right angles 
		\end{itemize}
		%todo image of H and L 
	\end{itemize}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Where is my research about?}
	\begin{itemize}
	\item  <+-| alert@+>{Annotation of urban scenes}
		\begin{itemize}
			\item  <+-| alert@+> Skyline detection
				\fig{outputSkylineSpil-Im29.eps}{width=200px}
			\item  <+-| alert@+> 3D building reconstruction
				% todo plaatje floriande -> 3d model
				\fig{3dModel}{width=200px}
			\item  <+-| alert@+> Window detection
		\end{itemize}
	\end{itemize}

	%todo insert TOC at every section
}

\section{Skylinedetection}
%-------------------------------------------------------------------
\frame
{
	\frametitle{Application examples of annotation of urban scenes}
	%What can we do with this annotation of urban scenes?}
	\begin{itemize}
		\item  <+-| alert@+> 3D city models
		%todo image
		%todo paper downloaden met dat 3d city model plaatje, auters: muller en wonka
		\item  <+-| alert@+> Driving simulation
		\item  <+-| alert@+> Augmented reality
		%todo image
		\item  <+-| alert@+> Building recognition
		\item  <+-| alert@+> Analysis building deformation
		\begin{itemize}
			% todo foto van de detectie dingen van noord-zuidlijn
			\item  <+-| alert@+> 	'noord-zuidlijn'
		\end{itemize}
	\end{itemize}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Skyline detection application example}
	\begin{itemize}
		\item  <+-| alert@+> Horizon detection for Unmanned Air Vehicles
		%notes:used to stabilize the vehicle
		% todo vet plaatje op google vinden van een uav
		\fig{p_uav_skyline_all.eps}{width=420px}
	\end{itemize}
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Skyline in urban scenes}% the method
	%we use it to detect the contour of the building
	\begin{itemize}
		\item  <+-| alert@+> Canny edge detection 
		\item  <+-| alert@+> Result: Binary image (edge or no edge)
		% evt computerprogrammatjuuuu
			%edge represents a high change in color 
		%\item  <+-| alert@+> Pre-precessing: Gaussian smoothing
		\item  <+-| alert@+> top sharp edge assumption\\
		\emph{"The first sharp edge (seen from top to bottom) in the image represents the skyline."}
	\end{itemize}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Skyline detection algorithm}% the method
	\begin{itemize}
		\item  <+-| alert@+> The image is sliced in \#w pixelcolumns
		\item  <+-| alert@+> Each column present \#h binary edge values (edge or no edge)
		\item  <+-| alert@+> y-location of the first edge value is stored 
	\end{itemize}
}



%-------------------------------------------------------------------
\frame
{
	\frametitle{Skyline detection Result}% the method
	\fig{e_floriande_canny_050.eps}
}

\subsection{Future research}
%-------------------------------------------------------------------
\frame
{
	\frametitle{Hypothesis based skyline detection, assumption}
	\emph{"The first sharp edge (seen from top to bottom) in the image represents the skyline."}
	\begin{itemize}
	\item  <+-| alert@+> Example of a scene where this assumption is violated
	\end{itemize}
	\fig{outputSkylineSpil-Im13-thresh030.eps}
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Hypothesis based skyline detection, assumption}
	\begin{itemize}
	\item  <+-| alert@+> Change of assumption
	\end{itemize}
	\emph{"The skyline is part of the first $n$ sharp edges (seen from top) (e.g.
	$n=3$)}
	\fig{folkert_edgeHypothesis.eps}
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Hypothesis based skyline detection, algorithm}
	\begin{itemize}
	\item  <+-| alert@+> Use exsisting column based approach
	\item  <+-| alert@+> Generate $n$ hypothesis
	\item  <+-| alert@+> classify hypothesis with additional info
		\begin{itemize}
		\item  <+-| alert@+> texture 
		\item  <+-| alert@+> color
		\item  <+-| alert@+> height variation 
		\end{itemize}
	\end{itemize}
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Expected result on hypothesis classification based on color}
	\fig{outputSkylineSpil-Im13-thresh070.eps}
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Expected result on hypothesis classification based on heigth variation}
	\fig{outputSkylineIm3-3-zoom.eps}
	\fig{outputSkylineIm3-3-zoom-con.eps}
}

	%todo close up skyline above sky below bricks
	%todo close up skyline above sky below sky (lamp) 


	%notes
	%The existing column based approach could be used to generate $n$ hypotheses and we can build
	%an algorithm on top of that to classify which hypothesis is right (i.e. which edge
	%presents the skyline).
	%
	%The hypothesis classifier must gather additional information. We could
	%discriminate the hypothesis for example by texture, color distributions or height
	%variation. We discuss the last two.


\section{Extracting the 3D model}
%-------------------------------------------------------------------
\frame
{
	\frametitle{Overview}
	%notes a skyline detection application
	\begin{itemize}
	\item  <+-| alert@+> Create (top view) 2D model of the scene using \emph{Openstreetmap}
	\fig{openstreetmap}
	\item  <+-| alert@+> Align 2D model with the scene using \emph{FIT3D toolbox}
	\item  <+-| alert@+> Transform the 2D model to a 3D model by extending the walls
	\end{itemize}
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Extract 2D model}
	\fig{openstreetmap}
	%--------notes----------------------------------------
	% whiteboard draw 2d model
	%-----------------------------------------------------
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Align 2D model}
	\begin{itemize}
	\item  <+-| alert@+> \emph{FIT3D toolbox}
	% out of the scope, is explained in my thesis
		\begin{itemize}
		\item  <+-| alert@+> Input: sequence of images that contain different views of the building
		\item  <+-| alert@+> Output: a 3D point cloud of the building
		\end{itemize}
	\figsHor{outputSkylineIm3-3.eps}{pc_3d.eps} %{ 3D point cloud of the walls of the building}{0.5}
	\end{itemize}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Align 2D model}
	\fig{pc_topview.eps} %{The projected 3D point cloud of the walls of the
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Align 2D model}
	\fig{pc_topview_linefit.eps} %{M2, The fitted line segments define (a top view of
	%---------------- notes ------------------------------
	% explain point to point correspondence 
	%-----------------------------------------------------
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Align 2D model}
	\fig{pc_topview2DModel.eps} %{The 2D model M1 aligned with the fitted line
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Results}
	\fig{3dModel} %{The basic 3D model, generated by extending the 
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Wall height estimation}
	% todo use this as a motivation for skyline detection
	\begin{itemize}
	%---------------- notes ------------------------------
	% because 3D model based on aerial images (openstreetmap)
	% -> Wall heights of 3D model are not accurate
	% explain point to point correspondence 
	% although it looks like a nice 3D model the wall heights..
	%-----------------------------------------------------
	%
	\item  <+-| alert@+> Wall heights of 3D model are not accurate
	\figsHor{3dModel}{floriande_back.eps} %{The walls of the building differ in height: the back
	\item  <+-| alert@+> Improve the 3D model by wall height estimation
	\end{itemize}
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Assumptions}
	%---------------- notes ------------------------------
	% Because we want to estimate the height of the building walls of the 3D
	% model, we need to know how high the walls in the 2D images are. 
	%---------------- notes ------------------------------
	\emph{Straight lines in the skyline are likely to come from the building contour}
	\emph{Flat roof assumption -> building contour is equal to upper side of building walls}
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Extracting line segments}
	% a widely used method for extracting line segments is the Hough transform
	\begin{itemize}
	\item  <+-| alert@+> Output of skyline detector
	%todo insert binary skyline image
	\item  <+-| alert@+> Hough transform
	\end{itemize}
	%---------------- notes ------------------------------
	% the technique behind this method is discussed in detail in my thesis
	% unfortunatelly, for now we don't have enough time to dive in to this topic
	%---------------- notes ------------------------------

	%\item  <+-| alert@+> Basic idea: Lines -> points in Hough space
	%\item  <+-| alert@+> Straight line segment that spans $y=mx+b$ represents $(m,b)$ point in Hough parameter space

	%---------------- notes ------------------------------
	% Because the algorithm detects straight lines containing only skyline pixels
	% it returns only the straight parts of the skyline.
	%---------------- notes ------------------------------
	\fig{outputHoughlines2d} %{Three best ranked lines of the Hough transform on the skyline detector match the three most prominent displayed building walls}{0.4}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Project to the 3D model}
	\begin{itemize}
	\item  <+-| alert@+> Estimate wall heights 
	\item  <+-| alert@+> project line segments to specific walls of 3D model
	\fig{coordinateSystemsCopy.eps} %{The blue line spanned by the camera center
	%---------------- notes ------------------------------
	% From image point (2D) to possible points in scene (3D)} 
	%---------------- notes ------------------------------
	\item  <+-| alert@+>
	\end{itemize}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Results 1/3}
	%\fignocaption{overlaytypes}{}{0.37}
	\fig{skyline_proj.eps} %{The Houghlines collected from different views projected on their corresponding
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Results 2/3}
	\fig{outputHoughlines3d} %{The Houghlines collected from different views re-projected on the 3D model according to the line-wall correspondence.}{0.5}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Results 3/3}
	\fig{outputMutateBuilding}{Improved 3D model}{0.6}
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Future research}
	%todo als tijd over

	%\fig{typesOfRoofs}{Different types of roofs}{0.4}
	%\fig{gableRoofWood.eps}{The parts of the 3D model for the Gable roof}{0.6}
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Overview}
	%todo highlight window detection
}




%-------------------------------------------------------------------
\frame
{
	\frametitle{Outline Window detection}
	%---------------- notes ------------------------------
	%recall that this thesis was about annotation of urban scenes
	%we annotated the 3D structure of the scene
	%next topic is window detection
	%---------------- notes ------------------------------
	\begin{itemize}
	\item  <+-| alert@+> Method I: Connected corner approach 
		\begin{itemize}
		\item  <+-| alert@+> invariant to viewing direction
		\end{itemize}
	\item  <+-| alert@+> Facade rectification 
	\item  <+-| alert@+> Method II: Histogram based approach
		\begin{itemize}
		\item  <+-| alert@+> rectified facades 
		\item  <+-| alert@+> uses Histograms of Houghlines
		\end{itemize}
	\end{itemize}
	% this will become clear when I explain it 
}

%-------------------------------------------------------------------
\frame
{
	\frametitle{Method I: Connected corner approach}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Situation}
	\begin{itemize}
	%---------------- notes ------------------------------
	%notes Window contains subwindows enclosed in rectangular window frames 
	%As the color of the window frames differ from the glass, the amount of
	%horizontal and vertical edges is large at these locations.  
	%Some horizontal and vertical edges come from the same window frame, therefore they often
	%---------------- notes ------------------------------
	\item  <+-| alert@+> Window frames 
	\item  <+-| alert@+> Difference color window frame, color glass
	\item  <+-| alert@+> Produce edges in horizontal and vertical direction
	\end{itemize}
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{The idea}
	\begin{itemize}
	\item  <+-| alert@+> Connected corner
	\item  <+-| alert@+> \emph{"horizontal and vertical edges that come from the same (sub)window frame share
	a corner"}
	\end{itemize}
	%todo plaatje van 1 raam met 1 connected corner
}


%-------------------------------------------------------------------
\frame
{
	\frametitle{Edge detection and Houghline extraction}
	%---------------- notes ------------------------------
	%edge detection -> straight lines 
	%---------------- notes ------------------------------
	%todo
	\begin{itemize}
	\item Canny edge detector
	\item Two groups of straight lines (Houghlines)
	\begin{itemize}
		\item Horizontal, $\theta = [-30..0..30)$ degrees
		%---------------- notes ------------------------------
		% theta = 0, horizontal   
		%---------------- notes ------------------------------
		\item Vertical, $\theta = [80..90..100)$ degrees
	\end{itemize}
	\item Why the use of angle ranges?
	\begin{itemize}
		\item Camera not exactly upright
		% (camera's roll factor)
		\item Facade view contains an angle, perspective distortion 
		%(camera's yaw factor)
	\end{itemize}
	\end{itemize}

}

\frame
{
	\frametitle{Original}
	\fig{w_Dirk6_ImOri.eps} 
	%--------------- notes --------------------------------
	% scene contains an everyday scene:
	% angle in viewing direction
	% different window types
	% light spot
	% occluding tree
	% bicycles 
	%--------------- notes --------------------------------
}

\frame
{
	\frametitle{Edge detection}
	\fig{w_Dirk6_ImEdge.eps}{Edge detection}{0.45}
}

\frame
{
	\frametitle{Result of $\theta$ constrained Hough transform}
	\fig{w_Dirk6_ImHoughResult.eps}
}

\frame
{
	\frametitle{Connected corner}
	\begin{itemize}
	\item Connected corner:a horizontal and vertical edge that share the same
	corner e.g. L
	\item Algorithm: If line segments endpoints are close enough a connected corner is formed
	\item Tolerate gab or extension
	\fig{cCornerTypes} %{First row: different type of connected corner candidates. Second row: the
	%--------------- notes --------------------------------
	% to form and clean up the connected corners..
	%--------------- notes --------------------------------
	\end{itemize}
}

\frame
{
	\frametitle{Connected Corners}
	\fig{w_Dirk6_ImcCorner_cCorner.eps} %{Found connected corners}{0.45}
	%--------------- notes --------------------------------
	% most of the connected corners are found to form and clean up the connected corners..
	%--------------- notes --------------------------------

}

\frame
{
	\frametitle{Window area extraction}
	\begin{itemize}
	\item Mirror from diagonal through endpoints
	\item L shape -> Quadrangle window area
	\end{itemize}
	%--------------- notes --------------------------------
	% whiteboard : draw L and rectangle with mirror line
	% if we overlap these areas we get this result
	%--------------- notes --------------------------------
}

\frame
{
	\frametitle{Results}
	\fig{w_Dirk6_ImcCorner_windowFilled.eps} %{Window regions}{0.45}
}

\frame
{
	\frametitle{Conclusion}
	\begin{itemize}
	\item The skyline deteciton algorithm 
		\begin{itemize}
		\item is simple and has a low complexity
		\item works wel under the assumption skyline is upper edge
		\item can provide a set of hypothesis which should be evaluated using andditional features
		\end{itemize}
	\end{itemize}
}

\frame
{
	\frametitle{Future research}
	\begin{itemize}
	\item L-shapes, U-shapes
		%--------------- notes --------------------------------
		% whiteboard : draw L and rectangle with mirror line
		% if we overlap these areas we get this result
		%--------------- notes --------------------------------
	\item analysis of substructure of windows
	\begin{itemize}
		\item define a contained in relations
		\item cluster connected corner on location and length
		\begin{itemize}
			\item maximum intercluster distance correlates with size subwindow
			\item assume nr of subwindows to estimate size
		\end{itemize}
	\end{itemize}
	\end{itemize}
}

\subsection{Method II: Histogram based approach} 
\frame
{
	\frametitle{Method II: window detection}
	\begin{itemize}
	\item Assumes that the windows are
	\begin{itemize}
		\item orthogonal
		%--------------- notes --------------------------------
		% orthogonal sides
		% angle between the horizontal and vertical parts is 90 degrees
		%--------------- notes --------------------------------
		\item aligned
		%--------------- notes --------------------------------
		% certain pattern in the windows
		% they are lined up in both horizontal as vertical direction
		% e.g. a row of windows share the same height
		%--------------- notes --------------------------------
	\end{itemize}
	\end{itemize}
		%--------------- notes --------------------------------
		%I exploited these properties to build a robust window detector
		%--------------- notes --------------------------------

}

\subsection{Facade rectification}
\frame
{
	\frametitle{Aligned but not orthogonal}
	\fig{w_spil6ImOri.eps} %{Dataset: Anne1, Original, (unrectified) image}{0.45}
}

\frame
{
	\frametitle{Rectified facade}
	\fig{w_Spil1TransCrop1_ImOri.eps}{Dataset: Anne1, Rectified image}{0.45}
}

\frame
{
	\frametitle{Facade rectification}
	\begin{itemize}
		\item 3D model gives plane that corresponds to wall
		\item wall produces a normal vector $b$
		\item camera's heading, $\vec{a}$
		\item rotation matrix R is calculated and applied
		%--------------- notes --------------------------------
		%by calculating angle diff of $a$ and $b$
		%apply on all points
		%--------------- notes --------------------------------
		\fig{axisAnglePresentation.eps}%{$\vec{a}$ is the camera's heading and $\vec{b}$
	\end{itemize}
}


\frame
{
	\frametitle{Unrectified facade}
	\fig{w_spil6ImOri.eps} %{Dataset: Anne1, Original, (unrectified) image}{0.45}
}

\frame
{
	\frametitle{Rectified facade}
	\fig{w_Spil1TransCrop1_ImOri.eps}{Dataset: Anne1, Rectified image}{0.45}
}

%--------------- notes --------------------------------
% we can also apply this on our other dataset
%--------------- notes --------------------------------

\frame
{
\fig{w_Dirk4_ImOri_Unrectified.eps} %{Dataset: Dirk, Original, (unrectified) image, }{0.45}
}

\frame
{
\fig{w_Dirk4Trans_ImOri.eps} %{Dataset: Dirk}{0.55}
}


\frame
{
	\frametitle{Extracting the window alignment}
	\begin{itemize}
	\item Window alignment line
	\begin{itemize}
		\item \emph{"A horizontal or vertical line that aligns multiple windows"}
	\end{itemize}
	\item Alignment lines provide grid of blocks
	\item Window non-window areas
	\end{itemize}
	
}


\frame
{
	\frametitle{Window alignment lines example}
	\fig{w_Spil1TransImproved_Xv.eps} %{Dataset: Anne2, Regular window alignment: based on a histogram that displays amount of overlapping vertical Hough lines at each $x$ position}{0.7}
}

\frame
{
	\frametitle{The idea}
	\item Amount of Houghlines high at window locations
	\fig{w_Spil1TransCrop1_ImHoughResult.eps}%{Dataset: Anne1, (Projected) Hough lines on rectified image}{0.45}
}

\frame
{
	\frametitle{The algorithm for vertical alignment (columns)}
	%----------------------- notes --------------------
	%----------------------- notes --------------------
	\begin{itemize}
	\item aim: get positions of window columns
	\item isolate $n$ horizontal Hough lines
	\item extract pixel coordinates of endpoints 
		\begin{itemize}
		\item ->set of (2 dimensional) coordinates (x,y)
		\end{itemize}
	%----------------------- notes --------------------
	% where h is the number of horizontal lines
	%----------------------- notes --------------------
	\item discard least informative dimension
		\begin{itemize}
		\item project to X-axis (by discard Y-value) 
		\item gives a set of $2n$ x values 
		\end{itemize}
	%----------------------- notes --------------------
	% where each scalar value presents a x coordinate
	%----------------------- notes --------------------
	\item Create histogram: count number of values on each x position
	%----------------------- notes --------------------
	% where w is the width of the image
	%----------------------- notes --------------------
	\end{itemize}
}

\frame
{
	\frametitle{Window alignment lines}
	\begin{itemize}
	%----------------------- notes --------------------
	% Peaks are located at position where an increased number of Houghlines start or end
	%----------------------- notes --------------------
	\fig{w_Spil1TransCrop1_ImHoughResult.eps}%
	\end{itemize}
}
\frame
{
	%todo mooi ingezoomed plaatje van een peak met threshold line
	\frametitle{Peak (area) extraction}
	\begin{itemize}
	\item smooth histogram function (red line) 
	\item relative threshold 0.5 * max peak defines peak areas
	\item locate maximum for each peak area
	\item draw alignment line on peaks
	%----------------------- notes --------------------
	% exploit concave shape of the peak area
	%----------------------- notes --------------------
	\fig{w_Spil1TransImproved_Xv.eps} %{Dataset: Anne2, Regular window alignment: based on a histogram that displays amount of overlapping vertical Hough lines at each $x$ position}{0.7}
	\end{itemize}
}


\frame
{
	\frametitle{Reasons for improvement}
	\begin{itemize}
	\item window alignment at wrong locations
	\item right side of window frame of first 4 columns not found
	\item main reason: perspective distortion creates occlusion effect
	\fig{w_Spil1TransImproved_Xv.eps} %{Dataset: Anne2, Regular window alignment: based on a histogram that displays amount of overlapping vertical Hough lines at each $x$ position}{0.7}
	\end{itemize}
}

\frame
{
\fig{w_Dirk4_ImOri_Unrectified.eps} %{Dataset: Dirk, Original, (unrectified) image, }{0.45}
}

\frame
{
	\frametitle{Alternative window alignment}
	\begin{itemize}
	\item Previous method: 
		\begin{itemize}
		\item line segment endpoints
		\item vertical lines -> window columns
		\item histogram peak detection
		\end{itemize}
	\item Alternative method: 
		\begin{itemize}
		\item entire line segment
		%------------- notes ----------------
		% this means longer lines have more influence which is desirable
		%------------- notes ----------------
		\item horizontal lines -> window columns
		\item histogram shape analysis
		\end{itemize}
	\end{itemize}
}

\frame
{
	\frametitle{Alternative window alignment}
	%------------- notes ----------------
	% this means longer lines have more influence which is desirable
	%------------- notes ----------------
	\begin{itemize}
	\item Idea
		\begin{itemize}
		\item a window frame creates horizontal edges
		\item on vertical alignment positions appears a big increase/decrease
		of horizontal lines as the window starts/end
		\end{itemize}
	\item X_{h} defines number of overlapping horizontal lines on each x
	position
	\item peak function \[D = abs( X_{h}')\]
	%------------- notes ----------------
	% deravitive because increase/decrease
	% abs to be big at both 
	%------------- notes ----------------
	\end{itemize}
}

\frame
{
\fig{w_Spil1TransImproved_Xh.eps}%{Dataset: Anne2, Alternative window alignment (orthogonal projection): Based on the shape of the smoothed histogram function. 
}




\frame
{
	\frametitle{Fusing the window alignment methods}
	\begin{itemize}
	\item plot both methods
	\item increase threshold (less but more certain alignment lines)
	\item merge peaks that are close
	\item plotting both methods
	\end{itemize}
}

\frame
{
	\fig{w_Spil1TransImproved_Xv.eps}{Dataset: Anne2, Regular window alignment: based on a histogram that displays amount of overlapping vertical Hough lines at each $x$ position}{0.7}
%------------- notes -------------------
% note that the right side of the windows is now correct detected
%------------- notes -------------------
}


\frame
{
	\fig{w_Dirk4Trans_ImOri.eps}% {Dataset: Dirk}{0.55}
}

\frame
{
	\fig{w_Dirk4_ImOri_Unrectified.eps} %{Dataset: Dirk, Original, (unrectified) image, }{0.45}
}

\frame
{
	\fig{w_Spil1TransImproved_Xvh.eps} %{Dataset: Anne2, Regular and alternative window alignment combined}{0.7}
}

\frame
{
	\fig{w_Dirk4Trans_ImHibaap_Xvh.eps} %{Dataset: Dirk, Regular and alternative window alignment combined}{0.45}
}


\frame
{
	\frametitle{Window classification}
	\begin{itemize}
	\item alignment lines -> grid of blocks
	\item classify blocks 
		\begin{itemize}
		\item window or non-window block
		\end{itemize}
	\end{itemize}
	\item Two methods:
	\item Basic classification 
		\begin{itemize}
		\item based on amount of Houghlines
		\end{itemize}
	\begin{itemize}
	\item Improved classification 
		\begin{itemize}
		\item based on shape of Histogram function
		%------------ notes ---------------
		% similar to window alignment method we just discussed 
		%------------ notes ---------------
		\end{itemize}
	\end{itemize}
}

\frame
{
	\frametitle{Basic window classification assumptions}
	\begin{itemize}
	\item Assumptions:
		\begin{itemize}
		\item a window block contains a high amount of Houghlines
		\item a non-window block contains low amount of Houghlines
		\item the windows are aligned 
			\begin{itemize}
			\item a row or column contains either zero windows or multiple windows 
			\end{itemize}
		\end{itemize}
	\end{itemize}
}

\frame
{
	\frametitle{Basic window classification algorithm}
	\begin{itemize}
	%------------ notes ---------------
	% instead of individual block classifaction..
	% more accurate
	%------------ notes ---------------
	\item exploit window alignment: classify full block rows and block columns
	\item count the nr of Houghlines in each blockrow
	\item discard blockrow size influence (normalize):
	\item \[\forall Ri\in \{1..numRows\} : R_i = \frac{HoughlinePxCount}{R_i^{width} \cdot R_i^{height}}\]
	\item output: ||R|| scalar values that ranks Rows being window area or not
	\end{itemize}
	

}

\frame
{
	\fig{w_Spil1TransCrop1_ImClassRectBarh.eps} %{Classification values for window
}

\frame
{
	\fig{w_Spil1TransCrop1_ImOri.eps} 
}

\frame
{
	\fig{w_Spil1TransCrop1_ImClassRectGrayscaleProb.eps} %{Dataset: Anne1, Basic window classification method:Measure of certainty, 
}


%todo kmeans plaatje jeeej

\frame
{
	\frametitle{From certainty to classification}
	\begin{itemize}
	% as we cope with two clusters non window and window areas
	\item $k$-means classification

	%------------- notes -----------------
	% how do we determine which value is clasified as high
	%------------- notes -----------------
	\end{itemize}
}

\frame
{
	\fig{w_Spil1TransCrop1_ImClassRect.eps} %{Dataset: Anne1, Basic window classification method: The extracted windows, red:the grouping}{0.65}
}

\frame
{
	\frametitle{Improved window classification}
	\begin{itemize}
	\item amount of Houghlines 
		\begin{itemize}
		\item increases towards center of window area
		\item decreases towards center of non-window area
		\end{itemize}
	\item amount of Houghlines increases towards center of window
	\item shape concave -> window area
	\item shape convex -> non-window area
	\end{itemize}
}
\frame
{
	\fig{w_Spil1TransImproved_WAlinesMerged.eps} %{Dataset: Anne2, Improved window
}

\frame
{
	\frametitle{Algorithm}
	\item detect concave and convex shape of histogram function $Xh$
	% derivative
	\item $X_{h}'$ 
	\item sign change of derivative indicates peak or valley
	\item (+,-) -> concave -> window area
	\item (-,+) -> convex -> non-window area
}

\frame
{
	\frametitle{Result}
	\fig{w_Spil1TransImproved_windowsGrouped.eps}{Dataset: Anne2, Improved window classification method: The extracted windows, red:the grouping}{0.7}
}

\frame
{
	\fig{w_Dirk4Trans_ImHibaap_WAlinesMerged.eps} %{Dataset: Dirk, Improved window
}

\frame
{
	\fig{w_Dirk4Trans_ImClassRect.eps} %{Dataset: Dirk, Improved window classification method: The extracted windows, red:the grouping}{0.40}
}

\frame
{
	\frametitle{Conclusions}
	\begin{itemize}
	\item Connected corner
		\begin{itemize}
		\item detection rate 97\%
		\item suitable for scenes with variation in window size/type
		\item small requirement on input data
			\item neither 3D information about building nor rectification is needed
		\item future research
			\begin{itemize}			
			\item U shapes 
			\item analysis of subwindow structure
			\end{itemize}			
		\end{itemize}
	\end{itemize}
}

\frame
{
	\fig{w_Dirk6_ImcCorner_cCorner.eps}{Found connected corners}{0.45}
}

\frame
{
	\fig{w_Dirk6_ImcCorner_windowFilled.eps}{Window regions}{0.45}
}

\frame
{
	\frametitle{Conclusion:Skyline detection}
	%todo
	\item simple
	\item low complexity
	\item workt without user interaction
	\item under the assumption that 
}

\frame
{
	\frametitle{Conclusion:Connected corner}
	\begin{itemize}
	\item detection rate 97\%
	\item suitable for scenes with variation in window size/type
	\item small requirement on input data
		\item neither 3D information about building nor rectification is needed
	\item future research
		\begin{itemize}			
		\item U shapes 
		\item analysis of subwindow structure
		\end{itemize}			
	\end{itemize}
}

\frame
{
	\frametitle{Conclusion:Histogram based window alignment}		

	\begin{itemize}
	\item interpreting amount of Houghlines strong approach towards window
	detection
	\item two window detection methods
	\item alternative window alignment performs better
		\begin{itemize}
		\item strong combination horizontal and vertical Houghlines histograms
		\item high order shape interpretation (derivative) of Histogram function
		\end{itemize}
	%todo tabel
	
	
	\end{itemize}

}
\frame
{
	\frametitle{Conclusion:window classification}		
	\begin{itemize}
	\item method I: based on amount of Houghlines
		\begin{itemize}
		\item performs quite good on the dataset we used
		\item very sensitive to alignment errors
		\item (errors in alignment propagate to classifications)
		\end{itemize}
	\item method II:based on shape of Houghlines Histogram
		\begin{itemize}
		\item strong increase/decrease of Houghlines
		\item very robust, at least 97\% detection rate on all datasets, why?
		\item higher order interpretation of Histogram function
		\item robust to alignment errors 
		% ------------ notes ----------------
		%	as long al the middle points fall in window non-window area
		% ------------------------------------
		\item the increase/decrease is relative
		\item robust to variation in window type and illumination conditions
		\end{itemize}
	\end{itemize}
}
%todo conclusions skyline detection

\frame
{
	\frametitle{Conclusion}		

	\begin{itemize}
	\item We retrieved semantics of urban scenes
		\begin{itemize}
		\item a full 3D reconstruction of a building
		\item extraction of windows
		\end{itemize}
	\end{itemize}
%---------------- notes ------------------
% although this is nothing compared to what humans see 
% we made a valueble start towards human-like interpretation of urban scenes
%-----------------------------------------
}

%
%	\subsubsection{Introduction}
%
%	\subsubsection{3D plane based rectification} 
%
%	\subsubsection{Results} % facade rectification
%
%	\subsection{Datasets}
%
%	\subsubsection{Anne1}
%
%	\subsubsection{Anne2}
%
%	\subsubsection{Dirk}
%
%	\subsection{Method II: Histogram based approach} 
%
%	\subsubsection{Introduction}
%
%	\subsubsection{Extracting the window alignment}
%
%	\subsubsection{Basic window classification (based on line amount)}
%
%	\subsubsection{Improved window classification (based on shape of the histogram function)}
%
%	%\subsubsection{Comparison of basic and improved window classification}
%
%	\subsection{Conclusion}
%
%	\subsubsection{Method I:Connected corner approach} % cCorner
%
%	\subsubsection{Method II: histogram based approach}









\section{Interactive demo}
	osgviewer demo of 3d point cloud and images
	demo of matlab progje


\subsection{Questions}
\frame{
\frametitle{Questions}
\begin{LARGE}
\begin{center}
 Questions?
\end{center}
\end{LARGE}
}

\end{document}
